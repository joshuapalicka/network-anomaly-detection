{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-08 17:39:20.227483: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "import autoencoder.aecExtraFeatures as Z_calculations\n",
    "\n",
    "def addZToPrediction(model, data_point):\n",
    "    reconstruction = model.decoder(model.encoder(data_point))\n",
    "\n",
    "    Z_features = Z_calculations.getZVector(data_point, reconstruction)\n",
    "\n",
    "    print(Z_features)\n",
    "    for feature in Z_features:\n",
    "        print(type(feature))\n",
    "\n",
    "    Z_features_tensor = tf.convert_to_tensor(Z_features)\n",
    "\n",
    "    data_point = tf.concat(data_point, Z_features_tensor)\n",
    "\n",
    "    return data_point"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def isAnomaly(data_point, model_1, model_2, threshold):\n",
    "\n",
    "    # need autoencoder to return boolean isAnomaly\n",
    "    isAnomaly = tf.math.less(tf.keras.losses.mae(model_1(data), data), threshold)\n",
    "\n",
    "    # if the autoencoder doesn't find anything out of the ordinary, return False\n",
    "    if not isAnomaly:\n",
    "        return False\n",
    "\n",
    "    data_point = addZToPrediction(model_1, data_point)\n",
    "\n",
    "    # if the autoencoder sees something weird, run it through the isolation forest to make sure\n",
    "    return model_2.predict(data_point)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('eda_simple_classification/network_data_mod_train.csv')\n",
    "test_data = pd.read_csv('eda_simple_classification/network_data_mod_test.csv')\n",
    "\n",
    "frames = [train_data, test_data]\n",
    "\n",
    "dataframe  = pd.concat(frames)\n",
    "raw_data = dataframe.values"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# The last element contains the labels\n",
    "labels = raw_data[:, -1]\n",
    "\n",
    "data = raw_data[:, 0:-1]\n",
    "\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(\n",
    "    data, labels, test_size=0.2, random_state=34\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-08 17:39:33.641022: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "min_val = tf.reduce_min(train_data)\n",
    "max_val = tf.reduce_max(train_data)\n",
    "\n",
    "train_data = (train_data - min_val) / (max_val - min_val)\n",
    "test_data = (test_data - min_val) / (max_val - min_val)\n",
    "\n",
    "train_data = tf.cast(train_data, tf.float32)\n",
    "test_data = tf.cast(test_data, tf.float32)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "train_labels = train_labels.astype(bool)\n",
    "test_labels = test_labels.astype(bool)\n",
    "\n",
    "normal_train_data = train_data[train_labels]\n",
    "normal_test_data = test_data[test_labels]\n",
    "\n",
    "anomalous_train_data = train_data[~train_labels]\n",
    "anomalous_test_data = test_data[~test_labels]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "from autoencoder.autoencoder import AnomalyDetector\n",
    "autoencoder = AnomalyDetector()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adam', loss='mae')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "Tensor(\"anomaly_detector/sequential/dense_2/Relu:0\", shape=(None, 8), dtype=float32)\n",
      "Tensor(\"anomaly_detector/sequential_1/dense_5/Sigmoid:0\", shape=(None, 47), dtype=float32)\n",
      "Tensor(\"anomaly_detector/sequential/dense_2/Relu:0\", shape=(None, 8), dtype=float32)\n",
      "Tensor(\"anomaly_detector/sequential_1/dense_5/Sigmoid:0\", shape=(None, 47), dtype=float32)\n",
      "1905/1927 [============================>.] - ETA: 0s - loss: 0.0144Tensor(\"anomaly_detector/sequential/dense_2/Relu:0\", shape=(None, 8), dtype=float32)\n",
      "Tensor(\"anomaly_detector/sequential_1/dense_5/Sigmoid:0\", shape=(None, 47), dtype=float32)\n",
      "1927/1927 [==============================] - 8s 3ms/step - loss: 0.0142 - val_loss: 4.1309e-04\n",
      "Epoch 2/5\n",
      "1927/1927 [==============================] - 4s 2ms/step - loss: 3.5210e-04 - val_loss: 3.5334e-04\n",
      "Epoch 3/5\n",
      "1927/1927 [==============================] - 4s 2ms/step - loss: 3.4082e-04 - val_loss: 3.1575e-04\n",
      "Epoch 4/5\n",
      "1927/1927 [==============================] - 4s 2ms/step - loss: 3.2043e-04 - val_loss: 2.6317e-04\n",
      "Epoch 5/5\n",
      "1927/1927 [==============================] - 5s 2ms/step - loss: 2.3473e-04 - val_loss: 2.0985e-04\n"
     ]
    }
   ],
   "source": [
    "history = autoencoder.fit(normal_train_data, normal_train_data,\n",
    "          epochs=5,\n",
    "          validation_data=(normal_test_data, normal_test_data),\n",
    "          shuffle=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"anomaly_detector/sequential/dense_2/Relu:0\", shape=(None, 8), dtype=float32)\n",
      "Tensor(\"anomaly_detector/sequential_1/dense_5/Sigmoid:0\", shape=(None, 47), dtype=float32)\n",
      "1927/1927 [==============================] - 3s 1ms/step\n",
      "Threshold:  0.00045557792\n"
     ]
    }
   ],
   "source": [
    "reconstructions = autoencoder.predict(normal_train_data)\n",
    "train_loss = tf.keras.losses.mae(reconstructions, normal_train_data)\n",
    "threshold = np.mean(train_loss) + np.std(train_loss)\n",
    "print(\"Threshold: \", threshold)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.003314836649224162, 0.999994695186615]\n",
      "<class 'float'>\n",
      "<class 'float'>\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "concat_dim: Tensor conversion requested dtype int32 for Tensor with dtype float32: <tf.Tensor: shape=(2,), dtype=float32, numpy=array([0.00331484, 0.9999947 ], dtype=float32)>",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[15], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m normal_train_data_with_Z \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;28mlen\u001B[39m(normal_train_data)):\n\u001B[0;32m----> 3\u001B[0m     normal_train_data_with_Z\u001B[38;5;241m.\u001B[39mappend(\u001B[43maddZToPrediction\u001B[49m\u001B[43m(\u001B[49m\u001B[43mautoencoder\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnormal_train_data\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m)\n",
      "Cell \u001B[0;32mIn[14], line 14\u001B[0m, in \u001B[0;36maddZToPrediction\u001B[0;34m(model, data_point)\u001B[0m\n\u001B[1;32m     10\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;28mtype\u001B[39m(feature))\n\u001B[1;32m     12\u001B[0m Z_features_tensor \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mconvert_to_tensor(Z_features, dtype\u001B[38;5;241m=\u001B[39mtf\u001B[38;5;241m.\u001B[39mfloat32)\n\u001B[0;32m---> 14\u001B[0m data_point \u001B[38;5;241m=\u001B[39m \u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconcat\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata_point\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mZ_features_tensor\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m data_point\n",
      "File \u001B[0;32m~/Documents/GitHub/network-anomaly-detection/venv/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:153\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m--> 153\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[1;32m    154\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    155\u001B[0m   \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[0;32m~/Documents/GitHub/network-anomaly-detection/venv/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:1597\u001B[0m, in \u001B[0;36mconvert_to_tensor\u001B[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001B[0m\n\u001B[1;32m   1595\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(value, Tensor):\n\u001B[1;32m   1596\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m dtype \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m dtype\u001B[38;5;241m.\u001B[39mis_compatible_with(value\u001B[38;5;241m.\u001B[39mdtype):\n\u001B[0;32m-> 1597\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m   1598\u001B[0m         _add_error_prefix(\n\u001B[1;32m   1599\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTensor conversion requested dtype \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdtype\u001B[38;5;241m.\u001B[39mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1600\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfor Tensor with dtype \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mvalue\u001B[38;5;241m.\u001B[39mdtype\u001B[38;5;241m.\u001B[39mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mvalue\u001B[38;5;132;01m!r}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   1601\u001B[0m             name\u001B[38;5;241m=\u001B[39mname))\n\u001B[1;32m   1602\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m value\n\u001B[1;32m   1604\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m preferred_dtype \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mValueError\u001B[0m: concat_dim: Tensor conversion requested dtype int32 for Tensor with dtype float32: <tf.Tensor: shape=(2,), dtype=float32, numpy=array([0.00331484, 0.9999947 ], dtype=float32)>"
     ]
    }
   ],
   "source": [
    "autoencoder.encoder(normal_train_data[20000:20001])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.003314836649224162, 0.999994695186615]\n",
      "<class 'float'>\n",
      "<class 'float'>\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "concat_dim: Tensor conversion requested dtype int32 for Tensor with dtype float32: <tf.Tensor: shape=(2,), dtype=float32, numpy=array([0.00331484, 0.9999947 ], dtype=float32)>",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[13], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m normal_train_data_with_Z \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;28mlen\u001B[39m(normal_train_data)):\n\u001B[0;32m----> 3\u001B[0m     normal_train_data_with_Z\u001B[38;5;241m.\u001B[39mappend(\u001B[43maddZToPrediction\u001B[49m\u001B[43m(\u001B[49m\u001B[43mautoencoder\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnormal_train_data\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m)\n",
      "Cell \u001B[0;32mIn[2], line 14\u001B[0m, in \u001B[0;36maddZToPrediction\u001B[0;34m(model, data_point)\u001B[0m\n\u001B[1;32m     10\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;28mtype\u001B[39m(feature))\n\u001B[1;32m     12\u001B[0m Z_features_tensor \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mconvert_to_tensor(Z_features)\n\u001B[0;32m---> 14\u001B[0m data_point \u001B[38;5;241m=\u001B[39m \u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconcat\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata_point\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mZ_features_tensor\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m data_point\n",
      "File \u001B[0;32m~/Documents/GitHub/network-anomaly-detection/venv/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:153\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m--> 153\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[1;32m    154\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    155\u001B[0m   \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[0;32m~/Documents/GitHub/network-anomaly-detection/venv/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:1597\u001B[0m, in \u001B[0;36mconvert_to_tensor\u001B[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001B[0m\n\u001B[1;32m   1595\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(value, Tensor):\n\u001B[1;32m   1596\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m dtype \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m dtype\u001B[38;5;241m.\u001B[39mis_compatible_with(value\u001B[38;5;241m.\u001B[39mdtype):\n\u001B[0;32m-> 1597\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m   1598\u001B[0m         _add_error_prefix(\n\u001B[1;32m   1599\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTensor conversion requested dtype \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdtype\u001B[38;5;241m.\u001B[39mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1600\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfor Tensor with dtype \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mvalue\u001B[38;5;241m.\u001B[39mdtype\u001B[38;5;241m.\u001B[39mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mvalue\u001B[38;5;132;01m!r}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   1601\u001B[0m             name\u001B[38;5;241m=\u001B[39mname))\n\u001B[1;32m   1602\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m value\n\u001B[1;32m   1604\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m preferred_dtype \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mValueError\u001B[0m: concat_dim: Tensor conversion requested dtype int32 for Tensor with dtype float32: <tf.Tensor: shape=(2,), dtype=float32, numpy=array([0.00331484, 0.9999947 ], dtype=float32)>"
     ]
    }
   ],
   "source": [
    "normal_train_data_with_Z = []\n",
    "for i in range(1, len(normal_train_data)):\n",
    "    normal_train_data_with_Z.append(addZToPrediction(autoencoder, normal_train_data[i-1:i]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_point = normal_train_data[:1]\n",
    "data_point"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
