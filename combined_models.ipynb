{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "import autoencoder.aecExtraFeatures as Z_calculations\n",
    "\n",
    "def addZToPrediction(model, data_point):\n",
    "    encoded = model.encoder(data_point)\n",
    "    reconstruction = model.decoder(encoded)\n",
    "\n",
    "    Z_features = [Z_calculations.getZVector(data_point, reconstruction, encoded)]\n",
    "\n",
    "    Z_features_tensor = tf.convert_to_tensor(Z_features, dtype=tf.float32)\n",
    "    data_point = tf.convert_to_tensor(data_point, dtype=tf.float32)\n",
    "\n",
    "    data_point = tf.concat([data_point, Z_features_tensor], 1)\n",
    "\n",
    "    return data_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "def isAnomaly(data_point, model_1, model_2, threshold):\n",
    "\n",
    "    # need autoencoder to return boolean isAnomaly\n",
    "    isAnomaly = tf.math.less(tf.keras.losses.mae(model_1(data_point), data_point), threshold)\n",
    "\n",
    "    # if the autoencoder doesn't find anything out of the ordinary, return False\n",
    "    if not isAnomaly:\n",
    "        return False\n",
    "\n",
    "    data_point = addZToPrediction(model_1, data_point)\n",
    "\n",
    "    # if the autoencoder sees something weird, run it through the isolation forest to make sure\n",
    "    return model_2.predict(data_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "from turtleIsolationForests.preprocessFeatures import preprocess_features\n",
    "\n",
    "train_dataframe = pd.read_csv(\"eda_simple_classification/network_data_mod_train.csv\", index_col=0)\n",
    "test_dataframe = pd.read_csv(\"eda_simple_classification/network_data_mod_test.csv\", index_col=0)\n",
    "\n",
    "train_data, test_data, train_labels, test_labels = preprocess_features(train_dataframe, test_dataframe)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "#train_data, test_data, train_labels, test_labels = train_data[:1000], test_data[:1000], train_labels[:1000], test_labels[:1000]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "np_train_labels = train_labels.to_numpy()\n",
    "np_test_labels = test_labels.to_numpy()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "np_train_data = train_data.to_numpy()\n",
    "np_test_data = test_data.to_numpy()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "np_train_data = tf.cast(np_train_data, tf.float32)\n",
    "np_test_data = tf.cast(np_test_data, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "np_train_labels = np_train_labels.astype(bool)\n",
    "np_test_labels = np_test_labels.astype(bool)\n",
    "\n",
    "normal_train_data = np_train_data[np_train_labels]\n",
    "normal_test_data = np_test_data[np_test_labels]\n",
    "\n",
    "anomalous_train_data = np_train_data[~np_train_labels]\n",
    "anomalous_test_data = np_test_data[~np_test_labels]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "from autoencoder.autoencoder import AnomalyDetector\n",
    "autoencoder = AnomalyDetector()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adam', loss='mae')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "Tensor(\"anomaly_detector_1/sequential_2/dense_8/Relu:0\", shape=(None, 8), dtype=float32)\n",
      "Tensor(\"anomaly_detector_1/sequential_3/dense_11/Sigmoid:0\", shape=(None, 46), dtype=float32)\n",
      "Tensor(\"anomaly_detector_1/sequential_2/dense_8/Relu:0\", shape=(None, 8), dtype=float32)\n",
      "Tensor(\"anomaly_detector_1/sequential_3/dense_11/Sigmoid:0\", shape=(None, 46), dtype=float32)\n",
      "2086/2105 [============================>.] - ETA: 0s - loss: 0.2904Tensor(\"anomaly_detector_1/sequential_2/dense_8/Relu:0\", shape=(None, 8), dtype=float32)\n",
      "Tensor(\"anomaly_detector_1/sequential_3/dense_11/Sigmoid:0\", shape=(None, 46), dtype=float32)\n",
      "2105/2105 [==============================] - 10s 4ms/step - loss: 0.2902 - val_loss: 0.4173\n",
      "Epoch 2/100\n",
      "2105/2105 [==============================] - 7s 3ms/step - loss: 0.2733 - val_loss: 0.4137\n",
      "Epoch 3/100\n",
      "2105/2105 [==============================] - 5s 2ms/step - loss: 0.2720 - val_loss: 0.4114\n",
      "Epoch 4/100\n",
      "2105/2105 [==============================] - 5s 3ms/step - loss: 0.2717 - val_loss: 0.4092\n",
      "Epoch 5/100\n",
      "2105/2105 [==============================] - 5s 3ms/step - loss: 0.2713 - val_loss: 0.4065\n",
      "Epoch 6/100\n",
      "2105/2105 [==============================] - 5s 3ms/step - loss: 0.2703 - val_loss: 0.4048\n",
      "Epoch 7/100\n",
      "2105/2105 [==============================] - 6s 3ms/step - loss: 0.2697 - val_loss: 0.4043\n",
      "Epoch 8/100\n",
      "2105/2105 [==============================] - 6s 3ms/step - loss: 0.2695 - val_loss: 0.4055\n",
      "Epoch 9/100\n",
      "2105/2105 [==============================] - 6s 3ms/step - loss: 0.2694 - val_loss: 0.4045\n",
      "Epoch 10/100\n",
      "2105/2105 [==============================] - 6s 3ms/step - loss: 0.2693 - val_loss: 0.4040\n",
      "Epoch 11/100\n",
      "2105/2105 [==============================] - 8s 4ms/step - loss: 0.2692 - val_loss: 0.4020\n",
      "Epoch 12/100\n",
      "2105/2105 [==============================] - 7s 3ms/step - loss: 0.2691 - val_loss: 0.4031\n",
      "Epoch 13/100\n",
      "2105/2105 [==============================] - 7s 3ms/step - loss: 0.2689 - val_loss: 0.4016\n",
      "Epoch 14/100\n",
      "2105/2105 [==============================] - 6s 3ms/step - loss: 0.2689 - val_loss: 0.4030\n",
      "Epoch 15/100\n",
      "2105/2105 [==============================] - 6s 3ms/step - loss: 0.2688 - val_loss: 0.4029\n",
      "Epoch 16/100\n",
      "2105/2105 [==============================] - 6s 3ms/step - loss: 0.2688 - val_loss: 0.4038\n",
      "Epoch 17/100\n",
      "2105/2105 [==============================] - 6s 3ms/step - loss: 0.2688 - val_loss: 0.4030\n",
      "Epoch 18/100\n",
      "2105/2105 [==============================] - 6s 3ms/step - loss: 0.2688 - val_loss: 0.4028\n",
      "Epoch 19/100\n",
      "2105/2105 [==============================] - 6s 3ms/step - loss: 0.2687 - val_loss: 0.4031\n",
      "Epoch 20/100\n",
      "2105/2105 [==============================] - 7s 3ms/step - loss: 0.2687 - val_loss: 0.4028\n",
      "Epoch 21/100\n",
      "2105/2105 [==============================] - 6s 3ms/step - loss: 0.2687 - val_loss: 0.4032\n",
      "Epoch 22/100\n",
      "2105/2105 [==============================] - 6s 3ms/step - loss: 0.2687 - val_loss: 0.4030\n",
      "Epoch 23/100\n",
      "2105/2105 [==============================] - 7s 3ms/step - loss: 0.2687 - val_loss: 0.4028\n",
      "Epoch 24/100\n",
      "2105/2105 [==============================] - 6s 3ms/step - loss: 0.2687 - val_loss: 0.4024\n",
      "Epoch 25/100\n",
      "2105/2105 [==============================] - 7s 3ms/step - loss: 0.2686 - val_loss: 0.4028\n",
      "Epoch 26/100\n",
      "2105/2105 [==============================] - 9s 4ms/step - loss: 0.2686 - val_loss: 0.4031\n",
      "Epoch 27/100\n",
      "2105/2105 [==============================] - 7s 3ms/step - loss: 0.2686 - val_loss: 0.4029\n",
      "Epoch 28/100\n",
      "2105/2105 [==============================] - 7s 3ms/step - loss: 0.2686 - val_loss: 0.4027\n",
      "Epoch 29/100\n",
      "2105/2105 [==============================] - 7s 3ms/step - loss: 0.2686 - val_loss: 0.4028\n",
      "Epoch 30/100\n",
      "2105/2105 [==============================] - 6s 3ms/step - loss: 0.2686 - val_loss: 0.4026\n",
      "Epoch 31/100\n",
      "2105/2105 [==============================] - 7s 3ms/step - loss: 0.2686 - val_loss: 0.4031\n",
      "Epoch 32/100\n",
      "2105/2105 [==============================] - 7s 3ms/step - loss: 0.2685 - val_loss: 0.4030\n",
      "Epoch 33/100\n",
      "2105/2105 [==============================] - 7s 3ms/step - loss: 0.2685 - val_loss: 0.4031\n",
      "Epoch 34/100\n",
      "2105/2105 [==============================] - 8s 4ms/step - loss: 0.2685 - val_loss: 0.4031\n",
      "Epoch 35/100\n",
      "2105/2105 [==============================] - 7s 3ms/step - loss: 0.2685 - val_loss: 0.4027\n",
      "Epoch 36/100\n",
      "2105/2105 [==============================] - 7s 3ms/step - loss: 0.2685 - val_loss: 0.4026\n",
      "Epoch 37/100\n",
      "2105/2105 [==============================] - 7s 3ms/step - loss: 0.2685 - val_loss: 0.4031\n",
      "Epoch 38/100\n",
      "2105/2105 [==============================] - 8s 4ms/step - loss: 0.2685 - val_loss: 0.4024\n",
      "Epoch 39/100\n",
      "2105/2105 [==============================] - 7s 4ms/step - loss: 0.2685 - val_loss: 0.4022\n",
      "Epoch 40/100\n",
      "2105/2105 [==============================] - 6s 3ms/step - loss: 0.2685 - val_loss: 0.4022\n",
      "Epoch 41/100\n",
      "2105/2105 [==============================] - 6s 3ms/step - loss: 0.2685 - val_loss: 0.4021\n",
      "Epoch 42/100\n",
      "2105/2105 [==============================] - 6s 3ms/step - loss: 0.2684 - val_loss: 0.4025\n",
      "Epoch 43/100\n",
      "2105/2105 [==============================] - 6s 3ms/step - loss: 0.2684 - val_loss: 0.4032\n",
      "Epoch 44/100\n",
      "2105/2105 [==============================] - 6s 3ms/step - loss: 0.2685 - val_loss: 0.4024\n",
      "Epoch 45/100\n",
      "2105/2105 [==============================] - 6s 3ms/step - loss: 0.2684 - val_loss: 0.4023\n",
      "Epoch 46/100\n",
      "2105/2105 [==============================] - 6s 3ms/step - loss: 0.2684 - val_loss: 0.4021\n",
      "Epoch 47/100\n",
      "2105/2105 [==============================] - 6s 3ms/step - loss: 0.2684 - val_loss: 0.4022\n",
      "Epoch 48/100\n",
      "2105/2105 [==============================] - 6s 3ms/step - loss: 0.2684 - val_loss: 0.4021\n",
      "Epoch 49/100\n",
      "2105/2105 [==============================] - 6s 3ms/step - loss: 0.2684 - val_loss: 0.4022\n",
      "Epoch 50/100\n",
      "2105/2105 [==============================] - 6s 3ms/step - loss: 0.2684 - val_loss: 0.4021\n",
      "Epoch 51/100\n",
      "2105/2105 [==============================] - 6s 3ms/step - loss: 0.2684 - val_loss: 0.4022\n",
      "Epoch 52/100\n",
      "2105/2105 [==============================] - 6s 3ms/step - loss: 0.2684 - val_loss: 0.4020\n",
      "Epoch 53/100\n",
      "2105/2105 [==============================] - 6s 3ms/step - loss: 0.2684 - val_loss: 0.4019\n",
      "Epoch 54/100\n",
      "2105/2105 [==============================] - 6s 3ms/step - loss: 0.2684 - val_loss: 0.4021\n",
      "Epoch 55/100\n",
      "2105/2105 [==============================] - 6s 3ms/step - loss: 0.2684 - val_loss: 0.4020\n",
      "Epoch 56/100\n",
      "2105/2105 [==============================] - 6s 3ms/step - loss: 0.2684 - val_loss: 0.4021\n",
      "Epoch 57/100\n",
      "2105/2105 [==============================] - 6s 3ms/step - loss: 0.2684 - val_loss: 0.4023\n",
      "Epoch 58/100\n",
      "2105/2105 [==============================] - 6s 3ms/step - loss: 0.2684 - val_loss: 0.4020\n",
      "Epoch 59/100\n",
      "2105/2105 [==============================] - 6s 3ms/step - loss: 0.2684 - val_loss: 0.4023\n",
      "Epoch 60/100\n",
      "2105/2105 [==============================] - 6s 3ms/step - loss: 0.2684 - val_loss: 0.4025\n",
      "Epoch 61/100\n",
      "2105/2105 [==============================] - 6s 3ms/step - loss: 0.2684 - val_loss: 0.4019\n",
      "Epoch 62/100\n",
      "2105/2105 [==============================] - 6s 3ms/step - loss: 0.2684 - val_loss: 0.4004\n",
      "Epoch 63/100\n",
      "2105/2105 [==============================] - 6s 3ms/step - loss: 0.2684 - val_loss: 0.4009\n",
      "Epoch 64/100\n",
      "2105/2105 [==============================] - 6s 3ms/step - loss: 0.2684 - val_loss: 0.4019\n",
      "Epoch 65/100\n",
      "2105/2105 [==============================] - 6s 3ms/step - loss: 0.2684 - val_loss: 0.4018\n",
      "Epoch 66/100\n",
      "2105/2105 [==============================] - 7s 3ms/step - loss: 0.2684 - val_loss: 0.4026\n",
      "Epoch 67/100\n",
      "2105/2105 [==============================] - 7s 3ms/step - loss: 0.2684 - val_loss: 0.4016\n",
      "Epoch 68/100\n",
      "2105/2105 [==============================] - 6s 3ms/step - loss: 0.2684 - val_loss: 0.4019\n",
      "Epoch 69/100\n",
      "2105/2105 [==============================] - 6s 3ms/step - loss: 0.2684 - val_loss: 0.4018\n",
      "Epoch 70/100\n",
      "2105/2105 [==============================] - 6s 3ms/step - loss: 0.2684 - val_loss: 0.4020\n",
      "Epoch 71/100\n",
      "2105/2105 [==============================] - 6s 3ms/step - loss: 0.2684 - val_loss: 0.4019\n",
      "Epoch 72/100\n",
      "2105/2105 [==============================] - 7s 3ms/step - loss: 0.2683 - val_loss: 0.4021\n",
      "Epoch 73/100\n",
      "2105/2105 [==============================] - 6s 3ms/step - loss: 0.2683 - val_loss: 0.4022\n",
      "Epoch 74/100\n",
      "2105/2105 [==============================] - 6s 3ms/step - loss: 0.2683 - val_loss: 0.4020\n",
      "Epoch 75/100\n",
      "2105/2105 [==============================] - 6s 3ms/step - loss: 0.2683 - val_loss: 0.4020\n",
      "Epoch 76/100\n",
      "2105/2105 [==============================] - 6s 3ms/step - loss: 0.2683 - val_loss: 0.4019\n",
      "Epoch 77/100\n",
      "2105/2105 [==============================] - 6s 3ms/step - loss: 0.2683 - val_loss: 0.4021\n",
      "Epoch 78/100\n",
      "2105/2105 [==============================] - 6s 3ms/step - loss: 0.2683 - val_loss: 0.4000\n",
      "Epoch 79/100\n",
      "2105/2105 [==============================] - 6s 3ms/step - loss: 0.2683 - val_loss: 0.4009\n",
      "Epoch 80/100\n",
      "2105/2105 [==============================] - 6s 3ms/step - loss: 0.2683 - val_loss: 0.4019\n",
      "Epoch 81/100\n",
      "2105/2105 [==============================] - 6s 3ms/step - loss: 0.2683 - val_loss: 0.4018\n",
      "Epoch 82/100\n",
      "2105/2105 [==============================] - 6s 3ms/step - loss: 0.2683 - val_loss: 0.4020\n",
      "Epoch 83/100\n",
      "2105/2105 [==============================] - 6s 3ms/step - loss: 0.2683 - val_loss: 0.4019\n",
      "Epoch 84/100\n",
      "2105/2105 [==============================] - 6s 3ms/step - loss: 0.2683 - val_loss: 0.4015\n",
      "Epoch 85/100\n",
      "2105/2105 [==============================] - 6s 3ms/step - loss: 0.2683 - val_loss: 0.4010\n",
      "Epoch 86/100\n",
      "2105/2105 [==============================] - 6s 3ms/step - loss: 0.2683 - val_loss: 0.4017\n",
      "Epoch 87/100\n",
      "2105/2105 [==============================] - 6s 3ms/step - loss: 0.2683 - val_loss: 0.4018\n",
      "Epoch 88/100\n",
      "2105/2105 [==============================] - 6s 3ms/step - loss: 0.2683 - val_loss: 0.4015\n",
      "Epoch 89/100\n",
      "2105/2105 [==============================] - 6s 3ms/step - loss: 0.2683 - val_loss: 0.4016\n",
      "Epoch 90/100\n",
      "2105/2105 [==============================] - 6s 3ms/step - loss: 0.2683 - val_loss: 0.4017\n",
      "Epoch 91/100\n",
      "2105/2105 [==============================] - 6s 3ms/step - loss: 0.2683 - val_loss: 0.4018\n",
      "Epoch 92/100\n",
      "2105/2105 [==============================] - 6s 3ms/step - loss: 0.2683 - val_loss: 0.4004\n",
      "Epoch 93/100\n",
      "2105/2105 [==============================] - 6s 3ms/step - loss: 0.2683 - val_loss: 0.4007\n",
      "Epoch 94/100\n",
      "2105/2105 [==============================] - 6s 3ms/step - loss: 0.2683 - val_loss: 0.4006\n",
      "Epoch 95/100\n",
      "2105/2105 [==============================] - 7s 3ms/step - loss: 0.2683 - val_loss: 0.4004\n",
      "Epoch 96/100\n",
      "2105/2105 [==============================] - 7s 3ms/step - loss: 0.2683 - val_loss: 0.4007\n",
      "Epoch 97/100\n",
      "2105/2105 [==============================] - 7s 3ms/step - loss: 0.2683 - val_loss: 0.4004\n",
      "Epoch 98/100\n",
      "2105/2105 [==============================] - 6s 3ms/step - loss: 0.2683 - val_loss: 0.4004\n",
      "Epoch 99/100\n",
      "2105/2105 [==============================] - 6s 3ms/step - loss: 0.2683 - val_loss: 0.4017\n",
      "Epoch 100/100\n",
      "2105/2105 [==============================] - 6s 3ms/step - loss: 0.2683 - val_loss: 0.4017\n"
     ]
    }
   ],
   "source": [
    "history = autoencoder.fit(normal_train_data, normal_train_data,\n",
    "          epochs=100,\n",
    "          validation_data=(test_data, test_data),\n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history[\"loss\"])\n",
    "plt.plot(history.history[\"val_loss\"])\n",
    "plt.title(\"Training Loss & Validation Loss over epochs\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "#plt.ylim([0,.0008])\n",
    "plt.legend([\"Loss\", \"Validation Loss\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"anomaly_detector_1/sequential_2/dense_8/Relu:0\", shape=(None, 8), dtype=float32)\n",
      "Tensor(\"anomaly_detector_1/sequential_3/dense_11/Sigmoid:0\", shape=(None, 46), dtype=float32)\n",
      "2105/2105 [==============================] - 3s 2ms/step\n",
      "Threshold:  0.44103524\n"
     ]
    }
   ],
   "source": [
    "reconstructions = autoencoder.predict(normal_train_data)\n",
    "train_loss = tf.keras.losses.mae(reconstructions, normal_train_data)\n",
    "threshold = np.mean(train_loss) + np.std(train_loss)\n",
    "print(\"Threshold: \", threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [],
   "source": [
    "def predict(model, data, threshold):\n",
    "  reconstructions = model(data)\n",
    "  loss = tf.keras.losses.mae(data, reconstructions) # 0 = anomaly (same as data)\n",
    "  return tf.math.less(loss, threshold)\n",
    "\n",
    "def getLoss(model, data):\n",
    "    reconstructions = model(data)\n",
    "    loss = tf.keras.losses.mae(data, reconstructions) # 0 = anomaly (same as data)\n",
    "    return loss\n",
    "\n",
    "def print_stats(predictions, labels):\n",
    "  print(\"Accuracy = {}\".format(accuracy_score(labels, predictions)))\n",
    "  print(\"Precision = {}\".format(precision_score(labels, predictions)))\n",
    "  print(\"Recall = {}\".format(recall_score(labels, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32.7 ms  3.64 ms per loop (mean  std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "%%capture\n",
    "\n",
    "predict(autoencoder, np_test_data, threshold)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "test_predictions = predict(autoencoder, np_test_data, threshold)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Stats for whole dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.7567423704755145\n",
      "Precision = 0.6441186498465735\n",
      "Recall = 0.972711358253527\n"
     ]
    }
   ],
   "source": [
    "print_stats(test_predictions, test_labels)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7614 5219]\n",
      " [ 265 9446]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(confusion_matrix(test_labels, test_predictions))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Stats for all predicted anomalous data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true anomalies: 9446\n",
      "false anomalies: 5219\n",
      "false normals: 265\n",
      "true normals: 7614\n",
      "precision: 0.6441186498465735\n",
      "recall: 0.972711358253527\n",
      "f1-score: 0.775024614374795\n"
     ]
    }
   ],
   "source": [
    "from pandas import DataFrame\n",
    "from turtleIsolationForests.printResults import print_results\n",
    "from turtleIsolationForests.printResults import get_auroc_value\n",
    "\n",
    "test_predictions_np = test_predictions.numpy()\n",
    "\n",
    "autoec_predictions = DataFrame()\n",
    "\n",
    "autoec_predictions['predicted_as_anomaly'] = test_predictions_np # 0: anomalous, 1: normal\n",
    "autoec_predictions['is_anomalous'] = test_labels # 0: normal, 1: anomalous\n",
    "autoec_predictions['anomaly_scores'] = getLoss(autoencoder, np_test_data)\n",
    "\n",
    "print_results(autoec_predictions)\n",
    "print(\"auroc: \" + str(get_auroc_value(autoec_predictions)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "def addZToData(data, model):\n",
    "    data_with_Z = []\n",
    "    for i in range(1, len(data)+1):\n",
    "        data_with_Z.append(addZToPrediction(model, data[i-1:i]))\n",
    "\n",
    "    data_with_Z_rf = []\n",
    "    for i in range(len(data_with_Z)):\n",
    "        data_with_Z_rf.append(np.append(np_train_data[:][:][i].numpy().reshape(1,46).squeeze(), data_with_Z[i]))\n",
    "\n",
    "    return pd.DataFrame(data_with_Z_rf)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [],
   "source": [
    "train_data_with_Z_df = addZToData(np_train_data, autoencoder)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "data": {
      "text/plain": "              0         1        2         3         4         5         6   \\\n0      -0.019113 -0.312889 -0.11205 -0.028606 -0.139982 -0.618438 -0.053906   \n1      -0.019113 -0.312889 -0.11205 -0.028606 -0.139982 -0.618438 -0.053906   \n2      -0.019113 -0.312889 -0.11205 -0.028606 -0.139982  1.616978 -0.053906   \n3      -0.019113 -0.312889 -0.11205 -0.028606 -0.139982 -0.618438 -0.053906   \n4      -0.019113 -0.312889 -0.11205 -0.028606 -0.139982 -0.618438 -0.053906   \n...          ...       ...      ...       ...       ...       ...       ...   \n125968 -0.019113 -0.312889 -0.11205 -0.028606 -0.139982  1.616978 -0.053906   \n125969 -0.019113 -0.312889 -0.11205 -0.028606 -0.139982 -0.618438 -0.053906   \n125970 -0.019113 -0.312889 -0.11205 -0.028606 -0.139982 -0.618438 -0.053906   \n125971 -0.019113 -0.312889 -0.11205 -0.028606 -0.139982  1.616978 -0.053906   \n125972 -0.019113 -0.312889 -0.11205 -0.028606 -0.139982 -0.618438 -0.053906   \n\n              7         8         9   ...        85        86        87  \\\n0      -0.031767 -0.019726  0.825150  ... -0.280282  0.069972 -0.289103   \n1      -0.031767 -0.019726  0.825150  ...  2.736852  2.367737 -0.289103   \n2      -0.031767 -0.019726 -1.211901  ... -0.174417 -0.480197 -0.289103   \n3      -0.031767 -0.019726  0.825150  ... -0.439078 -0.383108  0.066252   \n4      -0.031767 -0.019726  0.825150  ... -0.439078 -0.480197 -0.289103   \n...          ...       ...       ...  ...       ...       ...       ...   \n125968 -0.031767 -0.019726 -1.211901  ... -0.121485 -0.480197 -0.289103   \n125969 -0.031767 -0.019726  0.825150  ... -0.386146 -0.447834 -0.289103   \n125970 -0.031767 -0.019726  0.825150  ... -0.121485 -0.480197 -0.289103   \n125971 -0.031767 -0.019726 -1.211901  ... -0.174417 -0.480197 -0.289103   \n125972 -0.031767 -0.019726  0.825150  ... -0.280282  0.490690 -0.289103   \n\n              88        89        90        91        92        93        94  \n0      -0.639532 -0.624871 -0.224532 -0.376387  3.583353  2.395793  0.426715  \n1      -0.639532 -0.624871 -0.387635 -0.376387  5.872164  4.207399  0.514389  \n2       1.608759  1.618955 -0.387635 -0.376387  8.845963  4.824546 -0.307002  \n3      -0.572083 -0.602433 -0.387635 -0.345084  1.821037  2.350297  0.707768  \n4      -0.639532 -0.624871 -0.387635 -0.376387  0.084304  1.927049  0.788666  \n...          ...       ...       ...       ...       ...       ...       ...  \n125968  1.608759  1.618955 -0.387635 -0.376387  8.959674  4.794569 -0.261567  \n125969 -0.639532 -0.624871 -0.387635 -0.376387  0.249487  2.179151  0.680840  \n125970  0.979238 -0.624871 -0.355014 -0.376387  0.363633  2.441809  0.598059  \n125971  1.608759  1.618955 -0.387635 -0.376387  8.722095  4.892005 -0.297027  \n125972 -0.639532 -0.624871 -0.387635 -0.376387  1.496926  2.058905  0.675317  \n\n[125973 rows x 95 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>85</th>\n      <th>86</th>\n      <th>87</th>\n      <th>88</th>\n      <th>89</th>\n      <th>90</th>\n      <th>91</th>\n      <th>92</th>\n      <th>93</th>\n      <th>94</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0.019113</td>\n      <td>-0.312889</td>\n      <td>-0.11205</td>\n      <td>-0.028606</td>\n      <td>-0.139982</td>\n      <td>-0.618438</td>\n      <td>-0.053906</td>\n      <td>-0.031767</td>\n      <td>-0.019726</td>\n      <td>0.825150</td>\n      <td>...</td>\n      <td>-0.280282</td>\n      <td>0.069972</td>\n      <td>-0.289103</td>\n      <td>-0.639532</td>\n      <td>-0.624871</td>\n      <td>-0.224532</td>\n      <td>-0.376387</td>\n      <td>3.583353</td>\n      <td>2.395793</td>\n      <td>0.426715</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.019113</td>\n      <td>-0.312889</td>\n      <td>-0.11205</td>\n      <td>-0.028606</td>\n      <td>-0.139982</td>\n      <td>-0.618438</td>\n      <td>-0.053906</td>\n      <td>-0.031767</td>\n      <td>-0.019726</td>\n      <td>0.825150</td>\n      <td>...</td>\n      <td>2.736852</td>\n      <td>2.367737</td>\n      <td>-0.289103</td>\n      <td>-0.639532</td>\n      <td>-0.624871</td>\n      <td>-0.387635</td>\n      <td>-0.376387</td>\n      <td>5.872164</td>\n      <td>4.207399</td>\n      <td>0.514389</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0.019113</td>\n      <td>-0.312889</td>\n      <td>-0.11205</td>\n      <td>-0.028606</td>\n      <td>-0.139982</td>\n      <td>1.616978</td>\n      <td>-0.053906</td>\n      <td>-0.031767</td>\n      <td>-0.019726</td>\n      <td>-1.211901</td>\n      <td>...</td>\n      <td>-0.174417</td>\n      <td>-0.480197</td>\n      <td>-0.289103</td>\n      <td>1.608759</td>\n      <td>1.618955</td>\n      <td>-0.387635</td>\n      <td>-0.376387</td>\n      <td>8.845963</td>\n      <td>4.824546</td>\n      <td>-0.307002</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.019113</td>\n      <td>-0.312889</td>\n      <td>-0.11205</td>\n      <td>-0.028606</td>\n      <td>-0.139982</td>\n      <td>-0.618438</td>\n      <td>-0.053906</td>\n      <td>-0.031767</td>\n      <td>-0.019726</td>\n      <td>0.825150</td>\n      <td>...</td>\n      <td>-0.439078</td>\n      <td>-0.383108</td>\n      <td>0.066252</td>\n      <td>-0.572083</td>\n      <td>-0.602433</td>\n      <td>-0.387635</td>\n      <td>-0.345084</td>\n      <td>1.821037</td>\n      <td>2.350297</td>\n      <td>0.707768</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.019113</td>\n      <td>-0.312889</td>\n      <td>-0.11205</td>\n      <td>-0.028606</td>\n      <td>-0.139982</td>\n      <td>-0.618438</td>\n      <td>-0.053906</td>\n      <td>-0.031767</td>\n      <td>-0.019726</td>\n      <td>0.825150</td>\n      <td>...</td>\n      <td>-0.439078</td>\n      <td>-0.480197</td>\n      <td>-0.289103</td>\n      <td>-0.639532</td>\n      <td>-0.624871</td>\n      <td>-0.387635</td>\n      <td>-0.376387</td>\n      <td>0.084304</td>\n      <td>1.927049</td>\n      <td>0.788666</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>125968</th>\n      <td>-0.019113</td>\n      <td>-0.312889</td>\n      <td>-0.11205</td>\n      <td>-0.028606</td>\n      <td>-0.139982</td>\n      <td>1.616978</td>\n      <td>-0.053906</td>\n      <td>-0.031767</td>\n      <td>-0.019726</td>\n      <td>-1.211901</td>\n      <td>...</td>\n      <td>-0.121485</td>\n      <td>-0.480197</td>\n      <td>-0.289103</td>\n      <td>1.608759</td>\n      <td>1.618955</td>\n      <td>-0.387635</td>\n      <td>-0.376387</td>\n      <td>8.959674</td>\n      <td>4.794569</td>\n      <td>-0.261567</td>\n    </tr>\n    <tr>\n      <th>125969</th>\n      <td>-0.019113</td>\n      <td>-0.312889</td>\n      <td>-0.11205</td>\n      <td>-0.028606</td>\n      <td>-0.139982</td>\n      <td>-0.618438</td>\n      <td>-0.053906</td>\n      <td>-0.031767</td>\n      <td>-0.019726</td>\n      <td>0.825150</td>\n      <td>...</td>\n      <td>-0.386146</td>\n      <td>-0.447834</td>\n      <td>-0.289103</td>\n      <td>-0.639532</td>\n      <td>-0.624871</td>\n      <td>-0.387635</td>\n      <td>-0.376387</td>\n      <td>0.249487</td>\n      <td>2.179151</td>\n      <td>0.680840</td>\n    </tr>\n    <tr>\n      <th>125970</th>\n      <td>-0.019113</td>\n      <td>-0.312889</td>\n      <td>-0.11205</td>\n      <td>-0.028606</td>\n      <td>-0.139982</td>\n      <td>-0.618438</td>\n      <td>-0.053906</td>\n      <td>-0.031767</td>\n      <td>-0.019726</td>\n      <td>0.825150</td>\n      <td>...</td>\n      <td>-0.121485</td>\n      <td>-0.480197</td>\n      <td>-0.289103</td>\n      <td>0.979238</td>\n      <td>-0.624871</td>\n      <td>-0.355014</td>\n      <td>-0.376387</td>\n      <td>0.363633</td>\n      <td>2.441809</td>\n      <td>0.598059</td>\n    </tr>\n    <tr>\n      <th>125971</th>\n      <td>-0.019113</td>\n      <td>-0.312889</td>\n      <td>-0.11205</td>\n      <td>-0.028606</td>\n      <td>-0.139982</td>\n      <td>1.616978</td>\n      <td>-0.053906</td>\n      <td>-0.031767</td>\n      <td>-0.019726</td>\n      <td>-1.211901</td>\n      <td>...</td>\n      <td>-0.174417</td>\n      <td>-0.480197</td>\n      <td>-0.289103</td>\n      <td>1.608759</td>\n      <td>1.618955</td>\n      <td>-0.387635</td>\n      <td>-0.376387</td>\n      <td>8.722095</td>\n      <td>4.892005</td>\n      <td>-0.297027</td>\n    </tr>\n    <tr>\n      <th>125972</th>\n      <td>-0.019113</td>\n      <td>-0.312889</td>\n      <td>-0.11205</td>\n      <td>-0.028606</td>\n      <td>-0.139982</td>\n      <td>-0.618438</td>\n      <td>-0.053906</td>\n      <td>-0.031767</td>\n      <td>-0.019726</td>\n      <td>0.825150</td>\n      <td>...</td>\n      <td>-0.280282</td>\n      <td>0.490690</td>\n      <td>-0.289103</td>\n      <td>-0.639532</td>\n      <td>-0.624871</td>\n      <td>-0.387635</td>\n      <td>-0.376387</td>\n      <td>1.496926</td>\n      <td>2.058905</td>\n      <td>0.675317</td>\n    </tr>\n  </tbody>\n</table>\n<p>125973 rows  95 columns</p>\n</div>"
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_with_Z_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [],
   "source": [
    "np_test_labels = np.array(np_test_labels)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [],
   "source": [
    "predicted_anomalous = np_test_data[~test_predictions.numpy()]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_predictions.numpy()\n",
    "### should all be ones"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#predicted_anomalous.to_csv(\"predicted_anomalous.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "data": {
      "text/plain": "              0         1        2         3         4         5         6   \\\n0      -0.019113 -0.312889 -0.11205 -0.028606 -0.139982 -0.618438 -0.053906   \n1      -0.019113 -0.312889 -0.11205 -0.028606 -0.139982 -0.618438 -0.053906   \n2      -0.019113 -0.312889 -0.11205 -0.028606 -0.139982  1.616978 -0.053906   \n3      -0.019113 -0.312889 -0.11205 -0.028606 -0.139982 -0.618438 -0.053906   \n4      -0.019113 -0.312889 -0.11205 -0.028606 -0.139982 -0.618438 -0.053906   \n...          ...       ...      ...       ...       ...       ...       ...   \n125968 -0.019113 -0.312889 -0.11205 -0.028606 -0.139982  1.616978 -0.053906   \n125969 -0.019113 -0.312889 -0.11205 -0.028606 -0.139982 -0.618438 -0.053906   \n125970 -0.019113 -0.312889 -0.11205 -0.028606 -0.139982 -0.618438 -0.053906   \n125971 -0.019113 -0.312889 -0.11205 -0.028606 -0.139982  1.616978 -0.053906   \n125972 -0.019113 -0.312889 -0.11205 -0.028606 -0.139982 -0.618438 -0.053906   \n\n              7         8         9   ...        85        86        87  \\\n0      -0.031767 -0.019726  0.825150  ... -0.280282  0.069972 -0.289103   \n1      -0.031767 -0.019726  0.825150  ...  2.736852  2.367737 -0.289103   \n2      -0.031767 -0.019726 -1.211901  ... -0.174417 -0.480197 -0.289103   \n3      -0.031767 -0.019726  0.825150  ... -0.439078 -0.383108  0.066252   \n4      -0.031767 -0.019726  0.825150  ... -0.439078 -0.480197 -0.289103   \n...          ...       ...       ...  ...       ...       ...       ...   \n125968 -0.031767 -0.019726 -1.211901  ... -0.121485 -0.480197 -0.289103   \n125969 -0.031767 -0.019726  0.825150  ... -0.386146 -0.447834 -0.289103   \n125970 -0.031767 -0.019726  0.825150  ... -0.121485 -0.480197 -0.289103   \n125971 -0.031767 -0.019726 -1.211901  ... -0.174417 -0.480197 -0.289103   \n125972 -0.031767 -0.019726  0.825150  ... -0.280282  0.490690 -0.289103   \n\n              88        89        90        91        92        93        94  \n0      -0.639532 -0.624871 -0.224532 -0.376387  3.583353  2.395793  0.426715  \n1      -0.639532 -0.624871 -0.387635 -0.376387  5.872164  4.207399  0.514389  \n2       1.608759  1.618955 -0.387635 -0.376387  8.845963  4.824546 -0.307002  \n3      -0.572083 -0.602433 -0.387635 -0.345084  1.821037  2.350297  0.707768  \n4      -0.639532 -0.624871 -0.387635 -0.376387  0.084304  1.927049  0.788666  \n...          ...       ...       ...       ...       ...       ...       ...  \n125968  1.608759  1.618955 -0.387635 -0.376387  8.959674  4.794569 -0.261567  \n125969 -0.639532 -0.624871 -0.387635 -0.376387  0.249487  2.179151  0.680840  \n125970  0.979238 -0.624871 -0.355014 -0.376387  0.363633  2.441809  0.598059  \n125971  1.608759  1.618955 -0.387635 -0.376387  8.722095  4.892005 -0.297027  \n125972 -0.639532 -0.624871 -0.387635 -0.376387  1.496926  2.058905  0.675317  \n\n[125973 rows x 95 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>85</th>\n      <th>86</th>\n      <th>87</th>\n      <th>88</th>\n      <th>89</th>\n      <th>90</th>\n      <th>91</th>\n      <th>92</th>\n      <th>93</th>\n      <th>94</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0.019113</td>\n      <td>-0.312889</td>\n      <td>-0.11205</td>\n      <td>-0.028606</td>\n      <td>-0.139982</td>\n      <td>-0.618438</td>\n      <td>-0.053906</td>\n      <td>-0.031767</td>\n      <td>-0.019726</td>\n      <td>0.825150</td>\n      <td>...</td>\n      <td>-0.280282</td>\n      <td>0.069972</td>\n      <td>-0.289103</td>\n      <td>-0.639532</td>\n      <td>-0.624871</td>\n      <td>-0.224532</td>\n      <td>-0.376387</td>\n      <td>3.583353</td>\n      <td>2.395793</td>\n      <td>0.426715</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.019113</td>\n      <td>-0.312889</td>\n      <td>-0.11205</td>\n      <td>-0.028606</td>\n      <td>-0.139982</td>\n      <td>-0.618438</td>\n      <td>-0.053906</td>\n      <td>-0.031767</td>\n      <td>-0.019726</td>\n      <td>0.825150</td>\n      <td>...</td>\n      <td>2.736852</td>\n      <td>2.367737</td>\n      <td>-0.289103</td>\n      <td>-0.639532</td>\n      <td>-0.624871</td>\n      <td>-0.387635</td>\n      <td>-0.376387</td>\n      <td>5.872164</td>\n      <td>4.207399</td>\n      <td>0.514389</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0.019113</td>\n      <td>-0.312889</td>\n      <td>-0.11205</td>\n      <td>-0.028606</td>\n      <td>-0.139982</td>\n      <td>1.616978</td>\n      <td>-0.053906</td>\n      <td>-0.031767</td>\n      <td>-0.019726</td>\n      <td>-1.211901</td>\n      <td>...</td>\n      <td>-0.174417</td>\n      <td>-0.480197</td>\n      <td>-0.289103</td>\n      <td>1.608759</td>\n      <td>1.618955</td>\n      <td>-0.387635</td>\n      <td>-0.376387</td>\n      <td>8.845963</td>\n      <td>4.824546</td>\n      <td>-0.307002</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.019113</td>\n      <td>-0.312889</td>\n      <td>-0.11205</td>\n      <td>-0.028606</td>\n      <td>-0.139982</td>\n      <td>-0.618438</td>\n      <td>-0.053906</td>\n      <td>-0.031767</td>\n      <td>-0.019726</td>\n      <td>0.825150</td>\n      <td>...</td>\n      <td>-0.439078</td>\n      <td>-0.383108</td>\n      <td>0.066252</td>\n      <td>-0.572083</td>\n      <td>-0.602433</td>\n      <td>-0.387635</td>\n      <td>-0.345084</td>\n      <td>1.821037</td>\n      <td>2.350297</td>\n      <td>0.707768</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.019113</td>\n      <td>-0.312889</td>\n      <td>-0.11205</td>\n      <td>-0.028606</td>\n      <td>-0.139982</td>\n      <td>-0.618438</td>\n      <td>-0.053906</td>\n      <td>-0.031767</td>\n      <td>-0.019726</td>\n      <td>0.825150</td>\n      <td>...</td>\n      <td>-0.439078</td>\n      <td>-0.480197</td>\n      <td>-0.289103</td>\n      <td>-0.639532</td>\n      <td>-0.624871</td>\n      <td>-0.387635</td>\n      <td>-0.376387</td>\n      <td>0.084304</td>\n      <td>1.927049</td>\n      <td>0.788666</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>125968</th>\n      <td>-0.019113</td>\n      <td>-0.312889</td>\n      <td>-0.11205</td>\n      <td>-0.028606</td>\n      <td>-0.139982</td>\n      <td>1.616978</td>\n      <td>-0.053906</td>\n      <td>-0.031767</td>\n      <td>-0.019726</td>\n      <td>-1.211901</td>\n      <td>...</td>\n      <td>-0.121485</td>\n      <td>-0.480197</td>\n      <td>-0.289103</td>\n      <td>1.608759</td>\n      <td>1.618955</td>\n      <td>-0.387635</td>\n      <td>-0.376387</td>\n      <td>8.959674</td>\n      <td>4.794569</td>\n      <td>-0.261567</td>\n    </tr>\n    <tr>\n      <th>125969</th>\n      <td>-0.019113</td>\n      <td>-0.312889</td>\n      <td>-0.11205</td>\n      <td>-0.028606</td>\n      <td>-0.139982</td>\n      <td>-0.618438</td>\n      <td>-0.053906</td>\n      <td>-0.031767</td>\n      <td>-0.019726</td>\n      <td>0.825150</td>\n      <td>...</td>\n      <td>-0.386146</td>\n      <td>-0.447834</td>\n      <td>-0.289103</td>\n      <td>-0.639532</td>\n      <td>-0.624871</td>\n      <td>-0.387635</td>\n      <td>-0.376387</td>\n      <td>0.249487</td>\n      <td>2.179151</td>\n      <td>0.680840</td>\n    </tr>\n    <tr>\n      <th>125970</th>\n      <td>-0.019113</td>\n      <td>-0.312889</td>\n      <td>-0.11205</td>\n      <td>-0.028606</td>\n      <td>-0.139982</td>\n      <td>-0.618438</td>\n      <td>-0.053906</td>\n      <td>-0.031767</td>\n      <td>-0.019726</td>\n      <td>0.825150</td>\n      <td>...</td>\n      <td>-0.121485</td>\n      <td>-0.480197</td>\n      <td>-0.289103</td>\n      <td>0.979238</td>\n      <td>-0.624871</td>\n      <td>-0.355014</td>\n      <td>-0.376387</td>\n      <td>0.363633</td>\n      <td>2.441809</td>\n      <td>0.598059</td>\n    </tr>\n    <tr>\n      <th>125971</th>\n      <td>-0.019113</td>\n      <td>-0.312889</td>\n      <td>-0.11205</td>\n      <td>-0.028606</td>\n      <td>-0.139982</td>\n      <td>1.616978</td>\n      <td>-0.053906</td>\n      <td>-0.031767</td>\n      <td>-0.019726</td>\n      <td>-1.211901</td>\n      <td>...</td>\n      <td>-0.174417</td>\n      <td>-0.480197</td>\n      <td>-0.289103</td>\n      <td>1.608759</td>\n      <td>1.618955</td>\n      <td>-0.387635</td>\n      <td>-0.376387</td>\n      <td>8.722095</td>\n      <td>4.892005</td>\n      <td>-0.297027</td>\n    </tr>\n    <tr>\n      <th>125972</th>\n      <td>-0.019113</td>\n      <td>-0.312889</td>\n      <td>-0.11205</td>\n      <td>-0.028606</td>\n      <td>-0.139982</td>\n      <td>-0.618438</td>\n      <td>-0.053906</td>\n      <td>-0.031767</td>\n      <td>-0.019726</td>\n      <td>0.825150</td>\n      <td>...</td>\n      <td>-0.280282</td>\n      <td>0.490690</td>\n      <td>-0.289103</td>\n      <td>-0.639532</td>\n      <td>-0.624871</td>\n      <td>-0.387635</td>\n      <td>-0.376387</td>\n      <td>1.496926</td>\n      <td>2.058905</td>\n      <td>0.675317</td>\n    </tr>\n  </tbody>\n</table>\n<p>125973 rows  95 columns</p>\n</div>"
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_with_Z_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [],
   "source": [
    "predicted_anomalous_labels = np_test_labels[~test_predictions.numpy()]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predicted_anomalous_labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [],
   "source": [
    "anomalous_test_data_with_Z_df = addZToData(predicted_anomalous, autoencoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [],
   "source": [
    "contamination = sum(train_labels == 0) / len(train_labels)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [],
   "source": [
    "# need test_predictions replaced at indices that autoencoder predicted anomalies"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [
    {
     "data": {
      "text/plain": "             0         1        2         3         4         5         6   \\\n0     -0.019113 -0.312889 -0.11205 -0.028606 -0.139982 -0.618438 -0.053906   \n1     -0.019113 -0.312889 -0.11205 -0.028606 -0.139982 -0.618438 -0.053906   \n2     -0.019113 -0.312889 -0.11205 -0.028606 -0.139982  1.616978 -0.053906   \n3     -0.019113 -0.312889 -0.11205 -0.028606 -0.139982 -0.618438 -0.053906   \n4     -0.019113 -0.312889 -0.11205 -0.028606 -0.139982 -0.618438 -0.053906   \n...         ...       ...      ...       ...       ...       ...       ...   \n14660 -0.019113  3.196020 -0.11205 -0.028606 -0.139982 -0.618438 -0.053906   \n14661 -0.019113 -0.312889 -0.11205 -0.028606 -0.139982  1.616978 -0.053906   \n14662 -0.019113 -0.312889 -0.11205 -0.028606 -0.139982  1.616978 -0.053906   \n14663 -0.019113 -0.312889 -0.11205 -0.028606 -0.139982 -0.618438 -0.053906   \n14664 -0.019113  3.196020 -0.11205 -0.028606 -0.139982 -0.618438 -0.053906   \n\n             7         8         9   ...        85        86        87  \\\n0     -0.031767 -0.019726  0.825150  ... -0.227350  1.493939 -0.111426   \n1     -0.031767 -0.019726  0.825150  ... -0.439078  2.756092  2.198385   \n2     -0.031767 -0.019726 -1.211901  ... -0.439078 -0.447834 -0.022587   \n3     -0.031767 -0.019726  0.825150  ...  3.372038 -0.480197 -0.289103   \n4     -0.031767 -0.019726  0.825150  ... -0.439078 -0.447834 -0.022587   \n...         ...       ...       ...  ...       ...       ...       ...   \n14660 -0.031767 -0.019726 -1.211901  ... -0.439078  2.756092 -0.289103   \n14661 -0.031767 -0.019726 -1.211901  ... -0.121485 -0.447834 -0.200265   \n14662 -0.031767 -0.019726 -1.211901  ... -0.439078 -0.447834 -0.200265   \n14663 -0.031767 -0.019726  0.825150  ... -0.439078 -0.480197 -0.289103   \n14664 -0.031767 -0.019726 -1.211901  ... -0.386146 -0.480197 -0.289103   \n\n             88        89        90        91         92        93        94  \n0     -0.639532 -0.624871 -0.387635 -0.376387   6.180758  2.220589  0.643300  \n1     -0.639532 -0.624871 -0.387635 -0.376387  11.991243  5.293556  0.476488  \n2     -0.617049 -0.624871 -0.387635 -0.376387   1.656502  2.038718  0.756733  \n3     -0.639532 -0.624871  1.961037 -0.251175   0.763901  5.691018  0.304496  \n4     -0.639532 -0.624871 -0.387635 -0.376387   1.624299  1.946848  0.771669  \n...         ...       ...       ...       ...        ...       ...       ...  \n14660 -0.639532 -0.624871 -0.387635 -0.376387   4.593998  2.677897  0.784177  \n14661 -0.617049 -0.624871 -0.387635 -0.376387   2.240314  2.150332  0.629270  \n14662 -0.617049 -0.624871 -0.387635 -0.376387   0.696183  2.013179  0.761464  \n14663 -0.639532 -0.624871 -0.159292 -0.157266   0.000000  2.150937  0.753814  \n14664 -0.639532 -0.624871 -0.387635 -0.376387   0.176645  2.325461  0.669876  \n\n[14665 rows x 95 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>85</th>\n      <th>86</th>\n      <th>87</th>\n      <th>88</th>\n      <th>89</th>\n      <th>90</th>\n      <th>91</th>\n      <th>92</th>\n      <th>93</th>\n      <th>94</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0.019113</td>\n      <td>-0.312889</td>\n      <td>-0.11205</td>\n      <td>-0.028606</td>\n      <td>-0.139982</td>\n      <td>-0.618438</td>\n      <td>-0.053906</td>\n      <td>-0.031767</td>\n      <td>-0.019726</td>\n      <td>0.825150</td>\n      <td>...</td>\n      <td>-0.227350</td>\n      <td>1.493939</td>\n      <td>-0.111426</td>\n      <td>-0.639532</td>\n      <td>-0.624871</td>\n      <td>-0.387635</td>\n      <td>-0.376387</td>\n      <td>6.180758</td>\n      <td>2.220589</td>\n      <td>0.643300</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.019113</td>\n      <td>-0.312889</td>\n      <td>-0.11205</td>\n      <td>-0.028606</td>\n      <td>-0.139982</td>\n      <td>-0.618438</td>\n      <td>-0.053906</td>\n      <td>-0.031767</td>\n      <td>-0.019726</td>\n      <td>0.825150</td>\n      <td>...</td>\n      <td>-0.439078</td>\n      <td>2.756092</td>\n      <td>2.198385</td>\n      <td>-0.639532</td>\n      <td>-0.624871</td>\n      <td>-0.387635</td>\n      <td>-0.376387</td>\n      <td>11.991243</td>\n      <td>5.293556</td>\n      <td>0.476488</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0.019113</td>\n      <td>-0.312889</td>\n      <td>-0.11205</td>\n      <td>-0.028606</td>\n      <td>-0.139982</td>\n      <td>1.616978</td>\n      <td>-0.053906</td>\n      <td>-0.031767</td>\n      <td>-0.019726</td>\n      <td>-1.211901</td>\n      <td>...</td>\n      <td>-0.439078</td>\n      <td>-0.447834</td>\n      <td>-0.022587</td>\n      <td>-0.617049</td>\n      <td>-0.624871</td>\n      <td>-0.387635</td>\n      <td>-0.376387</td>\n      <td>1.656502</td>\n      <td>2.038718</td>\n      <td>0.756733</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.019113</td>\n      <td>-0.312889</td>\n      <td>-0.11205</td>\n      <td>-0.028606</td>\n      <td>-0.139982</td>\n      <td>-0.618438</td>\n      <td>-0.053906</td>\n      <td>-0.031767</td>\n      <td>-0.019726</td>\n      <td>0.825150</td>\n      <td>...</td>\n      <td>3.372038</td>\n      <td>-0.480197</td>\n      <td>-0.289103</td>\n      <td>-0.639532</td>\n      <td>-0.624871</td>\n      <td>1.961037</td>\n      <td>-0.251175</td>\n      <td>0.763901</td>\n      <td>5.691018</td>\n      <td>0.304496</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.019113</td>\n      <td>-0.312889</td>\n      <td>-0.11205</td>\n      <td>-0.028606</td>\n      <td>-0.139982</td>\n      <td>-0.618438</td>\n      <td>-0.053906</td>\n      <td>-0.031767</td>\n      <td>-0.019726</td>\n      <td>0.825150</td>\n      <td>...</td>\n      <td>-0.439078</td>\n      <td>-0.447834</td>\n      <td>-0.022587</td>\n      <td>-0.639532</td>\n      <td>-0.624871</td>\n      <td>-0.387635</td>\n      <td>-0.376387</td>\n      <td>1.624299</td>\n      <td>1.946848</td>\n      <td>0.771669</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>14660</th>\n      <td>-0.019113</td>\n      <td>3.196020</td>\n      <td>-0.11205</td>\n      <td>-0.028606</td>\n      <td>-0.139982</td>\n      <td>-0.618438</td>\n      <td>-0.053906</td>\n      <td>-0.031767</td>\n      <td>-0.019726</td>\n      <td>-1.211901</td>\n      <td>...</td>\n      <td>-0.439078</td>\n      <td>2.756092</td>\n      <td>-0.289103</td>\n      <td>-0.639532</td>\n      <td>-0.624871</td>\n      <td>-0.387635</td>\n      <td>-0.376387</td>\n      <td>4.593998</td>\n      <td>2.677897</td>\n      <td>0.784177</td>\n    </tr>\n    <tr>\n      <th>14661</th>\n      <td>-0.019113</td>\n      <td>-0.312889</td>\n      <td>-0.11205</td>\n      <td>-0.028606</td>\n      <td>-0.139982</td>\n      <td>1.616978</td>\n      <td>-0.053906</td>\n      <td>-0.031767</td>\n      <td>-0.019726</td>\n      <td>-1.211901</td>\n      <td>...</td>\n      <td>-0.121485</td>\n      <td>-0.447834</td>\n      <td>-0.200265</td>\n      <td>-0.617049</td>\n      <td>-0.624871</td>\n      <td>-0.387635</td>\n      <td>-0.376387</td>\n      <td>2.240314</td>\n      <td>2.150332</td>\n      <td>0.629270</td>\n    </tr>\n    <tr>\n      <th>14662</th>\n      <td>-0.019113</td>\n      <td>-0.312889</td>\n      <td>-0.11205</td>\n      <td>-0.028606</td>\n      <td>-0.139982</td>\n      <td>1.616978</td>\n      <td>-0.053906</td>\n      <td>-0.031767</td>\n      <td>-0.019726</td>\n      <td>-1.211901</td>\n      <td>...</td>\n      <td>-0.439078</td>\n      <td>-0.447834</td>\n      <td>-0.200265</td>\n      <td>-0.617049</td>\n      <td>-0.624871</td>\n      <td>-0.387635</td>\n      <td>-0.376387</td>\n      <td>0.696183</td>\n      <td>2.013179</td>\n      <td>0.761464</td>\n    </tr>\n    <tr>\n      <th>14663</th>\n      <td>-0.019113</td>\n      <td>-0.312889</td>\n      <td>-0.11205</td>\n      <td>-0.028606</td>\n      <td>-0.139982</td>\n      <td>-0.618438</td>\n      <td>-0.053906</td>\n      <td>-0.031767</td>\n      <td>-0.019726</td>\n      <td>0.825150</td>\n      <td>...</td>\n      <td>-0.439078</td>\n      <td>-0.480197</td>\n      <td>-0.289103</td>\n      <td>-0.639532</td>\n      <td>-0.624871</td>\n      <td>-0.159292</td>\n      <td>-0.157266</td>\n      <td>0.000000</td>\n      <td>2.150937</td>\n      <td>0.753814</td>\n    </tr>\n    <tr>\n      <th>14664</th>\n      <td>-0.019113</td>\n      <td>3.196020</td>\n      <td>-0.11205</td>\n      <td>-0.028606</td>\n      <td>-0.139982</td>\n      <td>-0.618438</td>\n      <td>-0.053906</td>\n      <td>-0.031767</td>\n      <td>-0.019726</td>\n      <td>-1.211901</td>\n      <td>...</td>\n      <td>-0.386146</td>\n      <td>-0.480197</td>\n      <td>-0.289103</td>\n      <td>-0.639532</td>\n      <td>-0.624871</td>\n      <td>-0.387635</td>\n      <td>-0.376387</td>\n      <td>0.176645</td>\n      <td>2.325461</td>\n      <td>0.669876</td>\n    </tr>\n  </tbody>\n</table>\n<p>14665 rows  95 columns</p>\n</div>"
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anomalous_test_data_with_Z_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [],
   "source": [
    "def getFinalPredictions(first_predictions, second_predictions):\n",
    "    autoencoder_copy = first_predictions.copy()\n",
    "    if_copy = second_predictions.copy()\n",
    "    indices = autoencoder_copy.index[autoencoder_copy[\"predicted_as_anomaly\"] == True]\n",
    "    if_copy.index = indices\n",
    "    autoencoder_copy.loc[indices, \"predicted_as_anomaly\"] = if_copy[\"predicted_as_anomaly\"]\n",
    "    print_results(autoencoder_copy)\n",
    "    print(\"auroc: \" + str(get_auroc_value(second_predictions)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [],
   "source": [
    "from turtleIsolationForests.extendedIsolationForest import ExtendedIsolationForest\n",
    "from turtleIsolationForests.printResults import print_results\n",
    "\n",
    "eif = ExtendedIsolationForest(contamination = contamination, random_state = None)\n",
    "eif.fit(train_data_with_Z_df, train_labels)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1min 3s  9.17 s per loop (mean  std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "eif.predict(anomalous_test_data_with_Z_df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true anomalies: 2069\n",
      "false anomalies: 2679\n",
      "false normals: 7642\n",
      "true normals: 10154\n",
      "precision: 0.4357624262847515\n",
      "recall: 0.21305735763567088\n",
      "f1-score: 0.28618853309357495\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'anomaly_score'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[0;32m~/Documents/GitHub/network-anomaly-detection/venv/lib/python3.8/site-packages/pandas/core/indexes/base.py:3802\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key, method, tolerance)\u001B[0m\n\u001B[1;32m   3801\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 3802\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcasted_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3803\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[0;32m~/Documents/GitHub/network-anomaly-detection/venv/lib/python3.8/site-packages/pandas/_libs/index.pyx:138\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m~/Documents/GitHub/network-anomaly-detection/venv/lib/python3.8/site-packages/pandas/_libs/index.pyx:165\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mKeyError\u001B[0m: 'anomaly_score'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[98], line 5\u001B[0m\n\u001B[1;32m      2\u001B[0m eif_predictions[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mis_normal\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m predicted_anomalous_labels\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m#print_results(eif_predictions)\u001B[39;00m\n\u001B[0;32m----> 5\u001B[0m \u001B[43mgetFinalPredictions\u001B[49m\u001B[43m(\u001B[49m\u001B[43mautoec_predictions\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43meif_predictions\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[95], line 8\u001B[0m, in \u001B[0;36mgetFinalPredictions\u001B[0;34m(first_predictions, second_predictions)\u001B[0m\n\u001B[1;32m      6\u001B[0m f_p_copy\u001B[38;5;241m.\u001B[39mloc[indices, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpredicted_as_anomaly\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m s_p_copy[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpredicted_as_anomaly\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m      7\u001B[0m print_results(f_p_copy)\n\u001B[0;32m----> 8\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mauroc: \u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mstr\u001B[39m(\u001B[43mget_auroc_value\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf_p_copy\u001B[49m\u001B[43m)\u001B[49m))\n",
      "File \u001B[0;32m~/Documents/GitHub/network-anomaly-detection/turtleIsolationForests/printResults.py:33\u001B[0m, in \u001B[0;36mget_auroc_value\u001B[0;34m(predictions)\u001B[0m\n\u001B[1;32m     32\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_auroc_value\u001B[39m(predictions: DataFrame) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mfloat\u001B[39m:\n\u001B[0;32m---> 33\u001B[0m     (fpr, tpr, _) \u001B[38;5;241m=\u001B[39m \u001B[43mget_auroc_points\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpredictions\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     34\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m get_auc(fpr, tpr)\n",
      "File \u001B[0;32m~/Documents/GitHub/network-anomaly-detection/turtleIsolationForests/printResults.py:38\u001B[0m, in \u001B[0;36mget_auroc_points\u001B[0;34m(predictions)\u001B[0m\n\u001B[1;32m     36\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_auroc_points\u001B[39m(predictions: DataFrame):\n\u001B[1;32m     37\u001B[0m     y_true \u001B[38;5;241m=\u001B[39m predictions[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mis_normal\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m---> 38\u001B[0m     y_score \u001B[38;5;241m=\u001B[39m \u001B[43mpredictions\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43manomaly_score\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\n\u001B[1;32m     39\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m roc_curve(y_true, y_score, pos_label\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n",
      "File \u001B[0;32m~/Documents/GitHub/network-anomaly-detection/venv/lib/python3.8/site-packages/pandas/core/frame.py:3807\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   3805\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mnlevels \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m   3806\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_multilevel(key)\n\u001B[0;32m-> 3807\u001B[0m indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3808\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[1;32m   3809\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m [indexer]\n",
      "File \u001B[0;32m~/Documents/GitHub/network-anomaly-detection/venv/lib/python3.8/site-packages/pandas/core/indexes/base.py:3804\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key, method, tolerance)\u001B[0m\n\u001B[1;32m   3802\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine\u001B[38;5;241m.\u001B[39mget_loc(casted_key)\n\u001B[1;32m   3803\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[0;32m-> 3804\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[1;32m   3805\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[1;32m   3806\u001B[0m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[1;32m   3807\u001B[0m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[1;32m   3808\u001B[0m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[1;32m   3809\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_indexing_error(key)\n",
      "\u001B[0;31mKeyError\u001B[0m: 'anomaly_score'"
     ]
    }
   ],
   "source": [
    "eif_predictions = eif.predict(anomalous_test_data_with_Z_df)\n",
    "eif_predictions['is_anomalous'] = predicted_anomalous_labels\n",
    "\n",
    "#print_results(eif_predictions)\n",
    "getFinalPredictions(autoec_predictions, eif_predictions)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true anomalies: 2069\n",
      "false anomalies: 2679\n",
      "false normals: 7642\n",
      "true normals: 10154\n",
      "precision: 0.4357624262847515\n",
      "recall: 0.21305735763567088\n",
      "f1-score: 0.28618853309357495\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'anomaly_score'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[0;32m~/Documents/GitHub/network-anomaly-detection/venv/lib/python3.8/site-packages/pandas/core/indexes/base.py:3802\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key, method, tolerance)\u001B[0m\n\u001B[1;32m   3801\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 3802\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcasted_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3803\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[0;32m~/Documents/GitHub/network-anomaly-detection/venv/lib/python3.8/site-packages/pandas/_libs/index.pyx:138\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m~/Documents/GitHub/network-anomaly-detection/venv/lib/python3.8/site-packages/pandas/_libs/index.pyx:165\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mKeyError\u001B[0m: 'anomaly_score'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[101], line 5\u001B[0m\n\u001B[1;32m      2\u001B[0m eif_predictions[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mis_normal\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m predicted_anomalous_labels_swap\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m#print_results(eif_predictions)\u001B[39;00m\n\u001B[0;32m----> 5\u001B[0m \u001B[43mgetFinalPredictions\u001B[49m\u001B[43m(\u001B[49m\u001B[43mautoec_predictions\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43meif_predictions\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[95], line 8\u001B[0m, in \u001B[0;36mgetFinalPredictions\u001B[0;34m(first_predictions, second_predictions)\u001B[0m\n\u001B[1;32m      6\u001B[0m f_p_copy\u001B[38;5;241m.\u001B[39mloc[indices, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpredicted_as_anomaly\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m s_p_copy[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpredicted_as_anomaly\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m      7\u001B[0m print_results(f_p_copy)\n\u001B[0;32m----> 8\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mauroc: \u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mstr\u001B[39m(\u001B[43mget_auroc_value\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf_p_copy\u001B[49m\u001B[43m)\u001B[49m))\n",
      "File \u001B[0;32m~/Documents/GitHub/network-anomaly-detection/turtleIsolationForests/printResults.py:33\u001B[0m, in \u001B[0;36mget_auroc_value\u001B[0;34m(predictions)\u001B[0m\n\u001B[1;32m     32\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_auroc_value\u001B[39m(predictions: DataFrame) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mfloat\u001B[39m:\n\u001B[0;32m---> 33\u001B[0m     (fpr, tpr, _) \u001B[38;5;241m=\u001B[39m \u001B[43mget_auroc_points\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpredictions\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     34\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m get_auc(fpr, tpr)\n",
      "File \u001B[0;32m~/Documents/GitHub/network-anomaly-detection/turtleIsolationForests/printResults.py:38\u001B[0m, in \u001B[0;36mget_auroc_points\u001B[0;34m(predictions)\u001B[0m\n\u001B[1;32m     36\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_auroc_points\u001B[39m(predictions: DataFrame):\n\u001B[1;32m     37\u001B[0m     y_true \u001B[38;5;241m=\u001B[39m predictions[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mis_normal\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m---> 38\u001B[0m     y_score \u001B[38;5;241m=\u001B[39m \u001B[43mpredictions\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43manomaly_score\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\n\u001B[1;32m     39\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m roc_curve(y_true, y_score, pos_label\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n",
      "File \u001B[0;32m~/Documents/GitHub/network-anomaly-detection/venv/lib/python3.8/site-packages/pandas/core/frame.py:3807\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   3805\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mnlevels \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m   3806\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_multilevel(key)\n\u001B[0;32m-> 3807\u001B[0m indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3808\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[1;32m   3809\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m [indexer]\n",
      "File \u001B[0;32m~/Documents/GitHub/network-anomaly-detection/venv/lib/python3.8/site-packages/pandas/core/indexes/base.py:3804\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key, method, tolerance)\u001B[0m\n\u001B[1;32m   3802\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine\u001B[38;5;241m.\u001B[39mget_loc(casted_key)\n\u001B[1;32m   3803\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[0;32m-> 3804\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[1;32m   3805\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[1;32m   3806\u001B[0m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[1;32m   3807\u001B[0m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[1;32m   3808\u001B[0m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[1;32m   3809\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_indexing_error(key)\n",
      "\u001B[0;31mKeyError\u001B[0m: 'anomaly_score'"
     ]
    }
   ],
   "source": [
    "eif_predictions = eif.predict(anomalous_test_data_with_Z_df)\n",
    "eif_predictions['is_anomalous'] = predicted_anomalous_labels\n",
    "\n",
    "#print_results(eif_predictions)\n",
    "getFinalPredictions(autoec_predictions, eif_predictions)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_predictions = eif.train_scores\n",
    "train_predictions['is_anomalous'] = train_labels\n",
    "print_results(train_predictions)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from turtleIsolationForests.sciForest import SCIsolationForest\n",
    "\n",
    "scif = SCIsolationForest(contamination = contamination, num_hyperplanes_per_split=5, random_state = None)\n",
    "scif.fit(train_data_with_Z_df, train_labels)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%timeit\n",
    "\n",
    "scif.predict(anomalous_test_data_with_Z_df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scif_predictions = scif.predict(anomalous_test_data_with_Z_df)\n",
    "scif_predictions['is_anomalous'] = predicted_anomalous_labels\n",
    "\n",
    "#print_results(scif_predictions)\n",
    "getFinalPredictions(autoec_predictions, scif_predictions)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from turtleIsolationForests.isolationForest import IsolationForest\n",
    "\n",
    "isoforest = IsolationForest(contamination = contamination, random_state = None)\n",
    "isoforest.fit(train_data_with_Z_df, train_labels)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%timeit\n",
    "\n",
    "isoforest.predict(anomalous_test_data_with_Z_df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "isoforest_predictions = isoforest.predict(anomalous_test_data_with_Z_df)\n",
    "isoforest_predictions['is_anomalous'] = predicted_anomalous_labels\n",
    "\n",
    "#print_results(isoforest_predictions)\n",
    "getFinalPredictions(autoec_predictions, isoforest_predictions)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from turtleIsolationForests.FBIF import FBIsolationForest\n",
    "\n",
    "fbif = FBIsolationForest(contamination = contamination, random_state = None)\n",
    "fbif.fit(train_data_with_Z_df, train_labels)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%timeit\n",
    "\n",
    "fbif.predict(anomalous_test_data_with_Z_df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fbif_predictions = fbif.predict(anomalous_test_data_with_Z_df)\n",
    "fbif_predictions['is_anomalous'] = predicted_anomalous_labels\n",
    "\n",
    "#print_results(fbif_predictions)\n",
    "getFinalPredictions(autoec_predictions, fbif_predictions)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "bbc3c3d932324566a9bf4b4a52ddf64063695fc3adbf25b3fda92572428493bb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
