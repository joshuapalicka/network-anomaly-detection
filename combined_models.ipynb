{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "import autoencoder.aecExtraFeatures as Z_calculations\n",
    "\n",
    "def addZToPrediction(model, data_point):\n",
    "    reconstruction = model.decoder(model.encoder(data_point))\n",
    "\n",
    "    Z_features = [Z_calculations.getZVector(data_point, reconstruction)]\n",
    "\n",
    "    Z_features_tensor = tf.convert_to_tensor(Z_features, dtype=tf.float32)\n",
    "    data_point = tf.convert_to_tensor(data_point, dtype=tf.float32)\n",
    "\n",
    "    data_point = tf.concat([data_point, Z_features_tensor], 1)\n",
    "\n",
    "    return data_point"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def isAnomaly(data_point, model_1, model_2, threshold):\n",
    "\n",
    "    # need autoencoder to return boolean isAnomaly\n",
    "    isAnomaly = tf.math.less(tf.keras.losses.mae(model_1(data), data), threshold)\n",
    "\n",
    "    # if the autoencoder doesn't find anything out of the ordinary, return False\n",
    "    if not isAnomaly:\n",
    "        return False\n",
    "\n",
    "    data_point = addZToPrediction(model_1, data_point)\n",
    "\n",
    "    # if the autoencoder sees something weird, run it through the isolation forest to make sure\n",
    "    return model_2.predict(data_point)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('eda_simple_classification/network_data_mod_train.csv')\n",
    "test_data = pd.read_csv('eda_simple_classification/network_data_mod_test.csv')\n",
    "\n",
    "frames = [train_data, test_data]\n",
    "\n",
    "dataframe  = pd.concat(frames)\n",
    "raw_data = dataframe.values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# The last element contains the labels\n",
    "labels = raw_data[:, -1]\n",
    "\n",
    "data = raw_data[:, 0:-1]\n",
    "\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(\n",
    "    data, labels, test_size=0.2, random_state=34\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-13 15:50:11.134600: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "min_val = tf.reduce_min(train_data)\n",
    "max_val = tf.reduce_max(train_data)\n",
    "\n",
    "train_data = (train_data - min_val) / (max_val - min_val)\n",
    "test_data = (test_data - min_val) / (max_val - min_val)\n",
    "\n",
    "train_data = tf.cast(train_data, tf.float32)\n",
    "test_data = tf.cast(test_data, tf.float32)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "train_labels = train_labels.astype(bool)\n",
    "test_labels = test_labels.astype(bool)\n",
    "\n",
    "normal_train_data = train_data[train_labels]\n",
    "normal_test_data = test_data[test_labels]\n",
    "\n",
    "anomalous_train_data = train_data[~train_labels]\n",
    "anomalous_test_data = test_data[~test_labels]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "from autoencoder.autoencoder import AnomalyDetector\n",
    "autoencoder = AnomalyDetector()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adam', loss='mae')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "Tensor(\"anomaly_detector/sequential/dense_2/Relu:0\", shape=(None, 8), dtype=float32)\n",
      "Tensor(\"anomaly_detector/sequential_1/dense_5/Sigmoid:0\", shape=(None, 47), dtype=float32)\n",
      "Tensor(\"anomaly_detector/sequential/dense_2/Relu:0\", shape=(None, 8), dtype=float32)\n",
      "Tensor(\"anomaly_detector/sequential_1/dense_5/Sigmoid:0\", shape=(None, 47), dtype=float32)\n",
      "1916/1927 [============================>.] - ETA: 0s - loss: 0.0189Tensor(\"anomaly_detector/sequential/dense_2/Relu:0\", shape=(None, 8), dtype=float32)\n",
      "Tensor(\"anomaly_detector/sequential_1/dense_5/Sigmoid:0\", shape=(None, 47), dtype=float32)\n",
      "1927/1927 [==============================] - 9s 4ms/step - loss: 0.0188 - val_loss: 7.2902e-04\n",
      "Epoch 2/5\n",
      "1927/1927 [==============================] - 7s 4ms/step - loss: 5.7865e-04 - val_loss: 5.2556e-04\n",
      "Epoch 3/5\n",
      "1927/1927 [==============================] - 10s 5ms/step - loss: 5.0389e-04 - val_loss: 4.6977e-04\n",
      "Epoch 4/5\n",
      "1927/1927 [==============================] - 8s 4ms/step - loss: 4.8195e-04 - val_loss: 5.2137e-04\n",
      "Epoch 5/5\n",
      "1927/1927 [==============================] - 7s 3ms/step - loss: 4.7202e-04 - val_loss: 4.4706e-04\n",
      "Epoch 1/5\n",
      "Tensor(\"anomaly_detector_1/sequential_2/dense_8/Relu:0\", shape=(None, 8), dtype=float32)\n",
      "Tensor(\"anomaly_detector_1/sequential_3/dense_11/Sigmoid:0\", shape=(None, 47), dtype=float32)\n",
      "Tensor(\"anomaly_detector_1/sequential_2/dense_8/Relu:0\", shape=(None, 8), dtype=float32)\n",
      "Tensor(\"anomaly_detector_1/sequential_3/dense_11/Sigmoid:0\", shape=(None, 47), dtype=float32)\n",
      "1911/1927 [============================>.] - ETA: 0s - loss: 0.0184Tensor(\"anomaly_detector_1/sequential_2/dense_8/Relu:0\", shape=(None, 8), dtype=float32)\n",
      "Tensor(\"anomaly_detector_1/sequential_3/dense_11/Sigmoid:0\", shape=(None, 47), dtype=float32)\n",
      "1927/1927 [==============================] - 5s 2ms/step - loss: 0.0183 - val_loss: 6.3287e-04\n",
      "Epoch 2/5\n",
      "1927/1927 [==============================] - 5s 2ms/step - loss: 6.0145e-04 - val_loss: 5.9667e-04\n",
      "Epoch 3/5\n",
      "1927/1927 [==============================] - 6s 3ms/step - loss: 6.0288e-04 - val_loss: 6.7492e-04\n",
      "Epoch 4/5\n",
      "1927/1927 [==============================] - 6s 3ms/step - loss: 5.7854e-04 - val_loss: 5.6887e-04\n",
      "Epoch 5/5\n",
      "1927/1927 [==============================] - 8s 4ms/step - loss: 5.7523e-04 - val_loss: 5.7475e-04\n"
     ]
    }
   ],
   "source": [
    "history = autoencoder.fit(normal_train_data, normal_train_data,\n",
    "          epochs=5000,\n",
    "          validation_data=(normal_test_data, normal_test_data),\n",
    "          shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"anomaly_detector/sequential/dense_2/Relu:0\", shape=(None, 8), dtype=float32)\n",
      "Tensor(\"anomaly_detector/sequential_1/dense_5/Sigmoid:0\", shape=(None, 47), dtype=float32)\n",
      "3713/3713 [==============================] - 7s 2ms/step\n",
      "Threshold:  0.0008905766\n",
      "Tensor(\"anomaly_detector_1/sequential_2/dense_8/Relu:0\", shape=(None, 8), dtype=float32)\n",
      "Tensor(\"anomaly_detector_1/sequential_3/dense_11/Sigmoid:0\", shape=(None, 47), dtype=float32)\n",
      "3713/3713 [==============================] - 7s 2ms/step\n",
      "Threshold:  0.0010680482\n"
     ]
    }
   ],
   "source": [
    "reconstructions = autoencoder.predict(train_data)\n",
    "train_loss = tf.keras.losses.mae(reconstructions, train_data)\n",
    "threshold = np.mean(train_loss) + np.std(train_loss)\n",
    "print(\"Threshold: \", threshold)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_data_with_Z = []\n",
    "for i in range(1, len(train_data)+1):\n",
    "    train_data_with_Z.append(addZToPrediction(autoencoder, train_data[i-1:i]))\n",
    "\n",
    "train_data_with_Z_rf = []\n",
    "for i in range(len(train_data_with_Z)):\n",
    "    train_data_with_Z_rf.append(train_data[:][:][i].numpy().reshape(1,47).squeeze())\n",
    "\n",
    "train_data_with_Z_df = pd.DataFrame(train_data_with_Z_rf)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_data_with_Z = []\n",
    "for i in range(1, len(train_data)+1):\n",
    "    test_data_with_Z.append(addZToPrediction(autoencoder, test_data[i-1:i]))\n",
    "\n",
    "test_data_with_Z_rf = []\n",
    "for i in range(len(test_data_with_Z)):\n",
    "    test_data_with_Z_rf.append(test_data[:][:][i].numpy().reshape(1,47).squeeze())\n",
    "\n",
    "test_data_with_Z_df = pd.DataFrame(test_data_with_Z_rf)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [
    {
     "data": {
      "text/plain": "0.4811678856690766"
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contamination = sum(train_labels == 0) / len(train_labels)\n",
    "contamination"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [
    {
     "data": {
      "text/plain": "<turtleIsolationForests.extendedIsolationForest.ExtendedIsolationForest at 0x7fac1f0b39a0>"
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from turtleIsolationForests.extendedIsolationForest import ExtendedIsolationForest\n",
    "\n",
    "model = ExtendedIsolationForest(contamination = contamination, random_state = None)\n",
    "model.fit(train_data_with_Z_df)\n",
    "model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predictions = model.predict(test_data_with_Z_df)\n",
    "predictions['is_normal'] = test_labels\n",
    "predictions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print_results(predictions)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}