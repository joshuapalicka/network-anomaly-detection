{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import autoencoder.aecExtraFeatures as Z_calculations\n",
    "\n",
    "def addZToPrediction(model, data_point):\n",
    "    reconstruction = model.decoder(model.encoder(data_point))\n",
    "\n",
    "    Z_features = [Z_calculations.getZVector(data_point, reconstruction)]\n",
    "\n",
    "    Z_features_tensor = tf.convert_to_tensor(Z_features, dtype=tf.float32)\n",
    "    data_point = tf.convert_to_tensor(data_point, dtype=tf.float32)\n",
    "\n",
    "    data_point = tf.concat([data_point, Z_features_tensor], 1)\n",
    "\n",
    "    return data_point"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def isAnomaly(data_point, model_1, model_2, threshold):\n",
    "\n",
    "    # need autoencoder to return boolean isAnomaly\n",
    "    isAnomaly = tf.math.less(tf.keras.losses.mae(model_1(data), data), threshold)\n",
    "\n",
    "    # if the autoencoder doesn't find anything out of the ordinary, return False\n",
    "    if not isAnomaly:\n",
    "        return False\n",
    "\n",
    "    data_point = addZToPrediction(model_1, data_point)\n",
    "\n",
    "    # if the autoencoder sees something weird, run it through the isolation forest to make sure\n",
    "    return model_2.predict(data_point)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('eda_simple_classification/network_data_mod_train.csv')\n",
    "test_data = pd.read_csv('eda_simple_classification/network_data_mod_test.csv')\n",
    "\n",
    "frames = [train_data, test_data]\n",
    "\n",
    "dataframe  = pd.concat(frames)\n",
    "raw_data = dataframe.values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# The last element contains the labels\n",
    "labels = raw_data[:, -1]\n",
    "\n",
    "data = raw_data[:, 0:-1]\n",
    "\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(\n",
    "    data, labels, test_size=0.2, random_state=34\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "min_val = tf.reduce_min(train_data)\n",
    "max_val = tf.reduce_max(train_data)\n",
    "\n",
    "train_data = (train_data - min_val) / (max_val - min_val)\n",
    "test_data = (test_data - min_val) / (max_val - min_val)\n",
    "\n",
    "train_data = tf.cast(train_data, tf.float32)\n",
    "test_data = tf.cast(test_data, tf.float32)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "train_labels = train_labels.astype(bool)\n",
    "test_labels = test_labels.astype(bool)\n",
    "\n",
    "normal_train_data = train_data[train_labels]\n",
    "normal_test_data = test_data[test_labels]\n",
    "\n",
    "anomalous_train_data = train_data[~train_labels]\n",
    "anomalous_test_data = test_data[~test_labels]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "from autoencoder.autoencoder import AnomalyDetector\n",
    "autoencoder = AnomalyDetector()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adam', loss='mae')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "Tensor(\"anomaly_detector/sequential/dense_2/Relu:0\", shape=(None, 8), dtype=float32)\n",
      "Tensor(\"anomaly_detector/sequential_1/dense_5/Sigmoid:0\", shape=(None, 47), dtype=float32)\n",
      "Tensor(\"anomaly_detector/sequential/dense_2/Relu:0\", shape=(None, 8), dtype=float32)\n",
      "Tensor(\"anomaly_detector/sequential_1/dense_5/Sigmoid:0\", shape=(None, 47), dtype=float32)\n",
      "1890/1927 [============================>.] - ETA: 0s - loss: 0.0208Tensor(\"anomaly_detector/sequential/dense_2/Relu:0\", shape=(None, 8), dtype=float32)\n",
      "Tensor(\"anomaly_detector/sequential_1/dense_5/Sigmoid:0\", shape=(None, 47), dtype=float32)\n",
      "1927/1927 [==============================] - 4s 2ms/step - loss: 0.0205 - val_loss: 0.0016\n",
      "Epoch 2/5\n",
      "1927/1927 [==============================] - 3s 1ms/step - loss: 6.3419e-04 - val_loss: 5.8781e-04\n",
      "Epoch 3/5\n",
      "1927/1927 [==============================] - 3s 2ms/step - loss: 5.8659e-04 - val_loss: 5.9299e-04\n",
      "Epoch 4/5\n",
      "1927/1927 [==============================] - 3s 1ms/step - loss: 5.8147e-04 - val_loss: 5.6455e-04\n",
      "Epoch 5/5\n",
      "1927/1927 [==============================] - 3s 2ms/step - loss: 5.8031e-04 - val_loss: 6.2629e-04\n"
     ]
    }
   ],
   "source": [
    "history = autoencoder.fit(normal_train_data, normal_train_data,\n",
    "          epochs=5,\n",
    "          validation_data=(normal_test_data, normal_test_data),\n",
    "          shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"anomaly_detector/sequential/dense_2/Relu:0\", shape=(None, 8), dtype=float32)\n",
      "Tensor(\"anomaly_detector/sequential_1/dense_5/Sigmoid:0\", shape=(None, 47), dtype=float32)\n",
      "3713/3713 [==============================] - 3s 873us/step\n",
      "Threshold:  0.0011032214\n"
     ]
    }
   ],
   "source": [
    "reconstructions = autoencoder.predict(train_data)\n",
    "train_loss = tf.keras.losses.mae(reconstructions, train_data)\n",
    "threshold = np.mean(train_loss) + np.std(train_loss)\n",
    "print(\"Threshold: \", threshold)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "train_data_with_Z = []\n",
    "for i in range(1, len(normal_train_data)):\n",
    "    train_data_with_Z.append(addZToPrediction(autoencoder, normal_train_data[i-1:i]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(1, 47), dtype=float32, numpy=\narray([[4.5528370e-01, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n        0.0000000e+00, 0.0000000e+00, 7.9382717e-06, 0.0000000e+00,\n        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n        6.0330867e-04, 1.2304322e-03, 0.0000000e+00, 0.0000000e+00,\n        0.0000000e+00, 0.0000000e+00, 7.9382717e-06, 0.0000000e+00,\n        7.9382723e-08, 2.0242594e-03, 2.0242594e-03, 7.9382717e-06,\n        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n        0.0000000e+00, 0.0000000e+00, 0.0000000e+00]], dtype=float32)>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[:1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "data_point = train_data_with_Z[:1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "train_data_with_Z = train_data_with_Z[:100]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "rf_train_data_with_Z = []"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "for i in range(len(train_data_with_Z)):\n",
    "    rf_train_data_with_Z.append([item.numpy() for sublist in data_point for item in sublist])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "data": {
      "text/plain": "(1, 49)"
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([list(range(49))]).shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "data": {
      "text/plain": "(49,)"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_train_data_with_Z[:][0][0].shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "0.4811678856690766"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contamination = sum(train_labels == 0) / len(train_labels)\n",
    "contamination"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "array([1., 1., 0., ..., 0., 1., 0.])"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "train_data_with_Z_df = pd.DataFrame(train_data_with_Z)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                    0\n0   [0.4552837, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...\n1   [0.4552837, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...\n2   [0.4552837, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...\n3   [0.4552837, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...\n4   [0.4552837, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...\n..                                                ...\n95  [0.4552837, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...\n96  [0.4552837, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...\n97  [0.4552837, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...\n98  [0.4552837, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...\n99  [0.4552837, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...\n\n[100 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[0.4552837, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[0.4552837, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[0.4552837, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[0.4552837, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[0.4552837, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>[0.4552837, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>[0.4552837, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>[0.4552837, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>[0.4552837, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>[0.4552837, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows × 1 columns</p>\n</div>"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_with_Z_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'sample'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[34], line 4\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mturtleIsolationForests\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mextendedIsolationForest\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ExtendedIsolationForest\n\u001B[0;32m      3\u001B[0m model \u001B[38;5;241m=\u001B[39m ExtendedIsolationForest(contamination \u001B[38;5;241m=\u001B[39m contamination, random_state \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[1;32m----> 4\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_data_with_Z\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      5\u001B[0m model\n",
      "File \u001B[1;32mE:\\CodingProjects\\network-anomaly-detection\\turtleIsolationForests\\isolationForest.py:77\u001B[0m, in \u001B[0;36mIsolationForest.fit\u001B[1;34m(self, train_data)\u001B[0m\n\u001B[0;32m     76\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfit\u001B[39m(\u001B[38;5;28mself\u001B[39m, train_data: pd\u001B[38;5;241m.\u001B[39mDataFrame) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:                      \u001B[38;5;66;03m#the whole dataset, as a dataframe, processed and suitable for training\u001B[39;00m\n\u001B[1;32m---> 77\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mforest \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_make_tree(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_random_subsample(train_data)) \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_trees)]\n\u001B[0;32m     78\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mthreshold \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_calculate_anomaly_score_threshold(train_data)\n",
      "File \u001B[1;32mE:\\CodingProjects\\network-anomaly-detection\\turtleIsolationForests\\isolationForest.py:77\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m     76\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfit\u001B[39m(\u001B[38;5;28mself\u001B[39m, train_data: pd\u001B[38;5;241m.\u001B[39mDataFrame) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:                      \u001B[38;5;66;03m#the whole dataset, as a dataframe, processed and suitable for training\u001B[39;00m\n\u001B[1;32m---> 77\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mforest \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_make_tree(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_random_subsample\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_data\u001B[49m\u001B[43m)\u001B[49m) \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_trees)]\n\u001B[0;32m     78\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mthreshold \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_calculate_anomaly_score_threshold(train_data)\n",
      "File \u001B[1;32mE:\\CodingProjects\\network-anomaly-detection\\turtleIsolationForests\\isolationForest.py:71\u001B[0m, in \u001B[0;36mIsolationForest._random_subsample\u001B[1;34m(self, dataframe)\u001B[0m\n\u001B[0;32m     69\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_random_subsample\u001B[39m(\u001B[38;5;28mself\u001B[39m, dataframe: pd\u001B[38;5;241m.\u001B[39mDataFrame) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame:\n\u001B[0;32m     70\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_advance_random_state()\n\u001B[1;32m---> 71\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mdataframe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msample\u001B[49m(n \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msubsample_size,\n\u001B[0;32m     72\u001B[0m                             replace \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m     73\u001B[0m                             weights \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m     74\u001B[0m                             random_state \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrandom_state)\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'list' object has no attribute 'sample'"
     ]
    }
   ],
   "source": [
    "from turtleIsolationForests.extendedIsolationForest import ExtendedIsolationForest\n",
    "\n",
    "model = ExtendedIsolationForest(contamination = contamination, random_state = None)\n",
    "model.fit(train_data_with_Z_df)\n",
    "model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}