{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "from autoencoder.autoencoder import AnomalyDetector\n",
    "from turtleIsolationForests.preprocessFeatures import minmax_preprocess_features\n",
    "from turtleIsolationForests.printResults import calc_confusion\n",
    "from tensorflow.keras.losses import mae\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataframe = read_csv(\"./eda_simple_classification/network_data_mod_train.csv\", index_col=0)\n",
    "test_dataframe = read_csv(\"./eda_simple_classification/network_data_mod_test.csv\", index_col=0)\n",
    "X_train, X_test, train_labels, test_labels = minmax_preprocess_features(train_dataframe, test_dataframe)\n",
    "X_train_ae = X_train[train_labels]\n",
    "X_test_normals = X_test[test_labels]\n",
    "X_test_anomalies = X_test[~test_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoenc = AnomalyDetector()\n",
    "autoenc.compile(optimizer='adam', loss='mae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "val_losses = []\n",
    "test_normal_losses = []\n",
    "test_anomaly_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "while i < 5000:\n",
    "    history = autoenc.fit(X_train_ae, X_train_ae, initial_epoch=i, epochs=i+1, validation_split=0.2, shuffle=True)\n",
    "    reconstructions_n = autoenc.predict(X_test_normals)\n",
    "    reconstructions_a = autoenc.predict(X_test_anomalies)\n",
    "    test_loss_normal = mae(X_test_normals, reconstructions_n)\n",
    "    test_loss_anomaly = mae(X_test_anomalies, reconstructions_a)\n",
    "    test_loss_normal_m = np.mean(test_loss_normal)\n",
    "    test_loss_anomaly_m = np.mean(test_loss_anomaly)\n",
    "    print(\"test loss on normals: \" + str(test_loss_normal_m) + \", test loss on anomalies: \" + str(test_loss_anomaly_m))\n",
    "    losses.append(history.history[\"loss\"][0])\n",
    "    val_losses.append(history.history[\"val_loss\"][0])\n",
    "    test_normal_losses.append(test_loss_normal_m)\n",
    "    test_anomaly_losses.append(test_loss_anomaly_m)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses)\n",
    "plt.plot(val_losses)\n",
    "plt.plot(test_normal_losses)\n",
    "plt.plot(test_anomaly_losses)\n",
    "plt.title(\"Training, Validation, and Test Loss over epochs\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.ylim([0, .08])\n",
    "plt.legend([\"Loss\", \"Validation Loss\", \"Test Loss Normals\", \"Test Loss Anomalies\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.violinplot([test_loss_normal, test_loss_anomaly], showmeans=True, showmedians=False)\n",
    "plt.title(\"Distributions of test losses on normal and anomalous points at epoch 5000\")\n",
    "plt.legend([\"test loss normal\", \"test loss anomaly\"])\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "from turtleIsolationForests.printResults import calc_confusion, get_auroc_value, calc_f1, print_by_result\n",
    "test_labels_np = test_labels.to_numpy()\n",
    "start_time = time()\n",
    "#autoenc.threshold = np.mean(losses[-1])\n",
    "autoenc.threshold = (np.median(test_normal_losses[-1]) + np.median(test_anomaly_losses[-1])) / 2\n",
    "ae_scores, ae_predictions = autoenc.pipeline_predict(X_test, test_labels_np)\n",
    "ae_time = time() - start_time\n",
    "ae_TA, ae_FA, ae_FN, ae_TN = calc_confusion(ae_predictions, test_labels_np)\n",
    "ae_auroc = get_auroc_value(ae_scores, test_labels_np)\n",
    "ae_precision, ae_recall, ae_f1 = calc_f1(ae_TA, ae_FA, ae_FN, ae_TN)\n",
    "print(\"Autoencoder Results\")\n",
    "print_by_result(ae_TA, ae_FA, ae_FN, ae_TN, ae_precision, ae_recall, ae_f1)\n",
    "print(\"auroc: \" + str(ae_auroc))\n",
    "print(\"test set prediction time: \" + str(ae_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while i < 10000:\n",
    "    history = autoenc.fit(X_train_ae, X_train_ae, initial_epoch=i, epochs=i+1, validation_split=0.2, shuffle=True)\n",
    "    reconstructions_n = autoenc.predict(X_test_normals)\n",
    "    reconstructions_a = autoenc.predict(X_test_anomalies)\n",
    "    test_loss_normal = mae(X_test_normals, reconstructions_n)\n",
    "    test_loss_anomaly = mae(X_test_anomalies, reconstructions_a)\n",
    "    test_loss_normal_m = np.mean(test_loss_normal)\n",
    "    test_loss_anomaly_m = np.mean(test_loss_anomaly)\n",
    "    print(\"test loss on normals: \" + str(test_loss_normal_m) + \", test loss on anomalies: \" + str(test_loss_anomaly_m))\n",
    "    losses.append(history.history[\"loss\"][0])\n",
    "    val_losses.append(history.history[\"val_loss\"][0])\n",
    "    test_normal_losses.append(test_loss_normal_m)\n",
    "    test_anomaly_losses.append(test_loss_anomaly_m)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses)\n",
    "plt.plot(val_losses)\n",
    "plt.plot(test_normal_losses)\n",
    "plt.plot(test_anomaly_losses)\n",
    "plt.title(\"Training, Validation, and Test Loss over epochs\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.ylim([0, .08])\n",
    "plt.legend([\"Loss\", \"Validation Loss\", \"Test Loss Normals\", \"Test Loss Anomalies\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.violinplot([test_loss_normal, test_loss_anomaly], showmeans=True, showmedians=False)\n",
    "plt.title(\"Distributions of test losses on normal and anomalous points at epoch 10000\")\n",
    "plt.legend([\"test loss normal\", \"test loss anomaly\"])\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time()\n",
    "autoenc.threshold = np.mean(losses[-1])\n",
    "ae_scores, ae_predictions = autoenc.pipeline_predict(X_test, test_labels_np)\n",
    "ae_time = time() - start_time\n",
    "ae_TA, ae_FA, ae_FN, ae_TN = calc_confusion(ae_predictions, test_labels_np)\n",
    "ae_auroc = get_auroc_value(ae_scores, test_labels_np)\n",
    "ae_precision, ae_recall, ae_f1 = calc_f1(ae_TA, ae_FA, ae_FN, ae_TN)\n",
    "print(\"Autoencoder Results\")\n",
    "print_by_result(ae_TA, ae_FA, ae_FN, ae_TN, ae_precision, ae_recall, ae_f1)\n",
    "print(\"auroc: \" + str(ae_auroc))\n",
    "print(\"test set prediction time: \" + str(ae_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
