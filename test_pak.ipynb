{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from turtleIsolationForests.isolationForest import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataframe = pd.read_csv(\"./data_OHE.csv\", index_col=0)\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_dataframe = pd.read_csv(\"./test_data_OHE.csv\", index_col=0)\n",
    "test_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "train_labels = dataframe.xs('class_normal', axis='columns')\n",
    "\n",
    "for column in dataframe.columns:\n",
    "    if (column[0:6] == 'class_'):\n",
    "        dataframe.drop(column, axis='columns', inplace=True)\n",
    "\n",
    "test_labels = test_dataframe.xs('class_normal', axis='columns')\n",
    "\n",
    "for column in test_dataframe.columns:\n",
    "    if (column[0:6] == 'class_'):\n",
    "        test_dataframe.drop(column, axis='columns', inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "X_train = dataframe\n",
    "X_test = test_dataframe"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = pd.DataFrame(scaler.fit_transform(X_train), columns = X_train.columns)\n",
    "X_test = pd.DataFrame(scaler.transform(X_test), columns = X_test.columns)\n",
    "X_train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "contamination = sum(train_labels == 0) / len(train_labels)\n",
    "contamination"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "model = IsolationForest(contamination = contamination, random_state = None)\n",
    "model.fit(X_train)\n",
    "model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "model.threshold"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "predictions['is_normal'] = test_labels\n",
    "predictions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "true_anomaly = len(predictions[predictions['is_normal'] == 0 & (predictions['predicted_as_anomaly'] == True)])\n",
    "false_anomaly = len(predictions[predictions['is_normal'] == 0 & (predictions['predicted_as_anomaly'] == False)])\n",
    "false_normal = len(predictions[predictions['is_normal'] == 1 & (predictions['predicted_as_anomaly'] == True)])\n",
    "true_normal = len(predictions[predictions['is_normal'] == 1 & (predictions['predicted_as_anomaly'] == False)])\n",
    "\n",
    "precision = true_anomaly / (true_anomaly + false_anomaly)\n",
    "recall = true_anomaly / (true_anomaly + false_normal)\n",
    "f1 = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "print(\"precision: \" + str(precision))\n",
    "print(\"recall: \" + str(recall))\n",
    "print(\"f1-score: \" + str(f1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "predicted_list = list(predictions[\"predicted_as_anomaly\"])\n",
    "test_list = list(predictions[\"is_normal\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "model.threshold"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Questions:\n",
    "How do we obtain \"windows\" from our datasets?\n",
    "What should k be for our data? Look at paper\n",
    "How do we obtain our threshold? It would be a line between the average True point and average False point\n",
    "\"\"\"\n",
    "\n",
    "def pak(anomaly_segment_list, ground_truth, threshold,  k):\n",
    "    allAboveThreshold = True\n",
    "\n",
    "    for item in anomaly_segment_list:\n",
    "        if item <= threshold:\n",
    "            allAboveThreshold = False\n",
    "\n",
    "    if allAboveThreshold:\n",
    "        print(\"All above threshold\")\n",
    "        return True\n",
    "\n",
    "    numCorrectlyDetected = 0\n",
    "\n",
    "    for i in range(len(anomaly_segment_list)):\n",
    "        if anomaly_segment_list[i] == ground_truth[i]:\n",
    "            numCorrectlyDetected += 1\n",
    "\n",
    "    return numCorrectlyDetected / len(anomaly_segment_list) > k"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def makeWindows(list1, list2, numWindows):\n",
    "    anomaly_segment_lists = []\n",
    "    ground_truth_lists = []\n",
    "\n",
    "    windowSize = math.ceil(len(list1) / numWindows)\n",
    "    a_s_list = []\n",
    "    g_t_list = []\n",
    "    for i in range(len(list1)):\n",
    "        a_s_list.append(list1[i])\n",
    "        g_t_list.append(list2[i])\n",
    "        if i % windowSize == 0 and i != 0:\n",
    "            anomaly_segment_lists.append(a_s_list)\n",
    "            ground_truth_lists.append(g_t_list)\n",
    "            a_s_list = []\n",
    "            g_t_list = []\n",
    "    anomaly_segment_lists.append(a_s_list)\n",
    "    print(anomaly_segment_lists)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "l1, l2 = makeWindows(predicted_list, test_list, 100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "for i in range(len(l1)):\n",
    "    print(pak(l1[i], l2[i], model.threshold, .20))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e97064513f0d268e2f073204e543b8077386c7433ee9f7232070081c2302a999"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}